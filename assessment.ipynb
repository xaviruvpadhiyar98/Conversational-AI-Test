{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment: Sentiment Analysis with TAO and Riva\n",
    "Sentiment analysis is a type of text classification, a common NLP task. \n",
    "Using a pretrained language model, such as BERT, it is possible to train a text classification model to classify sentences among defined categories.  In the case of sentiment analysis, there are only two categories: positive and negative.\n",
    "\n",
    "<img src=\"images/assess/sentiment_analysis.png\">\n",
    "\n",
    "### Table of Contents\n",
    "[The Problem](#The-Problem)<br>\n",
    "[Scoring](#Scoring)<br>\n",
    "[Step 1: Prepare the Project](#Step-1:-Prepare-the-Project)<br>\n",
    "[Step 2: Train](#Step-2:-Train)<br>\n",
    "[Step 3: Infer and Evaluate](#Step-3:-Infer-and-Evaluate)<br>\n",
    "[Step 4: Export Custom Model](#Step-4:-Export-Custom-Model)<br>\n",
    "[Step 5: Build and Deploy with Riva](#Step-5:-Build-and-Deploy-with-Riva)<br>\n",
    "[Step 6: Start Riva Services](#Step-6:-Start-Riva-Services)<br>\n",
    "[Step 7: Submit You Assessment](#Step-7:-Submit-You-Assessment)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Dependencies\n",
    "The steps in this notebook assume that you have:\n",
    "\n",
    "1. **NGC Credentials**<br>Be sure you have added your NGC credential as described in the [NGC Setup notebook](003_Intro_NGC_Setup.ipynb).  If you have restarted the course instance, you will need to repeat this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"docker kill\" requires at least 1 argument.\n",
      "See 'docker kill --help'.\n",
      "\n",
      "Usage:  docker kill [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Kill one or more running containers\n",
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "# Start fresh...\n",
    "# Clear Docker containers\n",
    "!docker kill $(docker ps -q)\n",
    "# Check for clean environment - this should be empty\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The Problem\n",
    "\n",
    "### SST-2 Movie Reviews\n",
    "The [Stanford Sentiment Treebank v2 (SST-2)](https://nlp.stanford.edu/sentiment/index.html) dataset is a corpus with fully labeled (two classes: positive and negative) single sentences extracted from movie reviews. Your task is to train a model using the dataset and deploy it to Riva, where you can run inference using the Riva API.\n",
    "\n",
    "### Your Project\n",
    "You are provided with labeled training and validation datasets, `train_small.tsv` and `dev_small.tsv` for the project.  There is also a test set, `test.tsv`, for a final test of the model.  All datasets are contained in the `tao/data/SST-2` directory.  You can open any of these files to take a look at the actual data and format:\n",
    "* [train_small.tsv](tao/data/SST-2/train_small.tsv)\n",
    "* [dev_small.tsv](tao/data/SST-2/dev_small.tsv)\n",
    "* [test.tsv](tao/data/SST-2/test.tsv)\n",
    "\n",
    "Your assignment is to train a [text classification model](https://docs.nvidia.com/tao/tao-toolkit/text/nlp/text_classification.html) with TAO using the `tao text_classification` launch command. After training, you must export the custom model, then deploy it using Riva.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scoring\n",
    "You will be assessed on your ability to effectively and efficiently train and deploy the model.  This coding assessment is worth 70 points, divided as follows:\n",
    "\n",
    "### Rubric\n",
    "\n",
    "| Step                    | Graded                                                 | FIXMEs?  | Points |\n",
    "|-------------------------|--------------------------------------------------------|----------|--------|\n",
    "| 1. Prepare the Project  | Specs and path definitions (spec files are present)    |  1       | 5      |\n",
    "| 2. Train                | Efficient training parameters (faster training)        |  5       | 15     |\n",
    "| 3. Infer and Evaluate   | Achieve good inference performance (F1 value >= 88)    |  0       | 10     |\n",
    "| 4. Export Custom Model  | Export for Riva (model exported in correct format)   |  1       | 12     |\n",
    "| 5. Build and Deploy     | Riva ServiceMaker (correct models built and loaded)  |  2       | 14     |\n",
    "| 6. Start Riva         | Riva Server (correct config; models run)             |  1       | 14     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you are very capable at this point of building the project without any help at all, some scaffolding is provided, including specific names for variables.  This is for the benefit of the autograder, so please use these constructs for your assessment.  In addition, a copy of the latest output for your executed cells in some cases is saved in the `my_assessment` directory.  Along the way, there are a few opportunities to check your work to see if you are on the right track. \n",
    "\n",
    "Once you are confident that you've built a reliable model, follow the instructions for submission at the end of the notebook.\n",
    "\n",
    "### Resources and Hints\n",
    "\n",
    "* **[TAO User's Guide](https://docs.nvidia.com/tao/tao-toolkit/index.html)**<br>\n",
    "* **[Riva Speech Skills User's Guide](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/index.html)**<br>\n",
    "* **TAO Example**<br>\n",
    "Review what you've learned in the [NER Fine-Tuning](007_NLP_Finetune_NER.ipynb) notebook to train, infer, evaluate, and export a TAO model.  The `tao token_classification` commands are very similar to the `tao text_classification` commands.\n",
    "* **Riva Deployment Example**<br>\n",
    "Review what you've learned in the [NER Model Deployment with Riva](008_NLP_Deploy_NER.ipynb) notebook to build and deploy the model, as well as start the Riva server.\n",
    "* **AMP Optimization Level (trainer.amp_level):**<br>\n",
    "To use mixed precision, set AMP to 'O1' or 'O2'; to train without mixed precision, set it to 'O0'.\n",
    "* **Precision (trainer.precision):**<br>\n",
    "To speed up training, you can set the precision to 16 instead of the standard 32 with little or no loss in accuracy.\n",
    "* **Number of epochs (trainer.max_epochs):**<br>\n",
    "The project is designed so that you should achieve success on this dataset with only 2 epochs, but feel free to run more. On a Tesla T4, this takes 5-6 minutes if you run it efficiently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1: Prepare the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Project Paths (not graded)\n",
    "This block is complete, but feel free to add to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the TAO paths for the project\n",
    "##### TAO paths - source\n",
    "SOURCE_MOUNT=\"/dli/task/tao\"\n",
    "DESTINATION_MOUNT = \"/workspace/mount\"\n",
    "\n",
    "##### TAO paths - source\n",
    "# Define location of the SST-2 dataset\n",
    "DATA = SOURCE_MOUNT+'/data/SST-2'\n",
    "# Directory where the .riva model is stored\n",
    "EXPORT_MODEL_LOC = SOURCE_MOUNT + '/results/sst2/export'\n",
    "\n",
    "##### TAO paths - destination (from the perspective of the TAO Docker)\n",
    "# The path to the specification YAML \n",
    "SPECS_DIR = DESTINATION_MOUNT + '/specs'\n",
    "# The results are saved at this path by default\n",
    "RESULTS_DIR = DESTINATION_MOUNT + '/results'\n",
    "# The data are saved at this path by default\n",
    "DATA_DIR = DESTINATION_MOUNT + '/data'\n",
    "# The results are saved at this path by default\n",
    "MODELS_DIR = DESTINATION_MOUNT + '/models'\n",
    "\n",
    "# Set your encryption key, and use the same key for all commands. Please use \"tlt_encode\" if you'd like to deploy the models later with NVIDIA Riva.\n",
    "KEY = 'tlt_encode'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Spec Files (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 14:35:09,098 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 14:35:09,225 [INFO] tlt.components.docker_handler.docker_handler: The required docker doesn't exist locally/the manifest has changed. Pulling a new docker.\n",
      "2022-09-22 14:35:09,225 [INFO] tlt.components.docker_handler.docker_handler: Pulling the required container. This may take several minutes if you're doing this for the first time. Please wait here.\n",
      "...\n",
      "2022-09-22 14:37:41,063 [INFO] tlt.components.docker_handler.docker_handler: Container pull complete.\n",
      "2022-09-22 14:37:41,065 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 14:37:46 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo I 2022-09-22 14:37:48 tlt_logging:20] Experiment configuration:\n",
      "    exp_manager:\n",
      "      task_name: download_specs\n",
      "      explicit_log_dir: /workspace/mount/results\n",
      "    source_data_dir: /opt/conda/lib/python3.8/site-packages/nlp/text_classification/experiment_specs\n",
      "    target_data_dir: /workspace/mount/specs/text_classification\n",
      "    workflow: nlp\n",
      "    \n",
      "[NeMo I 2022-09-22 14:37:48 download_specs:73] Default specification files for nlp downloaded to '/workspace/mount/specs/text_classification'\n",
      "[NeMo I 2022-09-22 14:37:48 download_specs:74] Experiment logs saved to '/workspace/mount/results'\n",
      "2022-09-22 14:37:49,269 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n",
      "Repository name: nvcr.io/nvidia/tao/tao-toolkit-pyt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import rmtree\n",
    "\n",
    "# Delete the specs directory if it already exists\n",
    "folder = SOURCE_MOUNT + '/specs'\n",
    "if os.path.exists(folder):\n",
    "    rmtree(folder)\n",
    "\n",
    "# Get the text classification task spec files\n",
    "!tao text_classification download_specs \\\n",
    "    -o $SPECS_DIR/text_classification \\\n",
    "    -r $RESULTS_DIR \\\n",
    "    2>&1|tee my_assessment/step1.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Train\n",
    "### Run the Trainer (graded)\n",
    "Review the `train.yaml` file you've just downloaded. Run the trainer in TAO and override YAML config values as necessary.\n",
    "\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell. Feel free to add/remove override values as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 16:13:15,534 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 16:13:15,648 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 16:13:19 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-09-22 16:13:23 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-09-22 16:13:24 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: ???\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/sst2\n",
      "      exp_dir: null\n",
      "      name: trained-model\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: true\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .tlt\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    model:\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      language_model:\n",
      "        pretrained_model_name: bert-base-uncased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      classifier_head:\n",
      "        num_output_layers: 2\n",
      "        fc_dropout: 0.1\n",
      "      class_labels:\n",
      "        class_labels_file: /workspace/mount/data/SST-2/label_ids.csv\n",
      "      dataset:\n",
      "        num_classes: 2\n",
      "        do_lower_case: false\n",
      "        max_seq_length: 256\n",
      "        class_balancing: null\n",
      "        use_cache: false\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 2\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 16\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: O1\n",
      "    training_ds:\n",
      "      file_path: /workspace/mount/data/SST-2/train.tsv\n",
      "      batch_size: 64\n",
      "      shuffle: true\n",
      "      num_samples: -1\n",
      "      num_workers: 3\n",
      "      drop_last: false\n",
      "      pin_memory: false\n",
      "    validation_ds:\n",
      "      file_path: /workspace/mount/data/SST-2/test.tsv\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "      num_workers: 3\n",
      "      drop_last: false\n",
      "      pin_memory: false\n",
      "    optim:\n",
      "      name: adam\n",
      "      lr: 2.0e-05\n",
      "      betas:\n",
      "      - 0.9\n",
      "      - 0.999\n",
      "      weight_decay: 0.01\n",
      "      sched:\n",
      "        name: WarmupAnnealing\n",
      "        warmup_steps: null\n",
      "        warmup_ratio: 0.1\n",
      "        last_epoch: -1\n",
      "        monitor: val_loss\n",
      "        reduce_on_plateau: false\n",
      "    encryption_key: '**********'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "Using native 16bit precision.\n",
      "[NeMo W 2022-09-22 16:13:24 exp_manager:303] There was no checkpoint folder at checkpoint_dir :/workspace/mount/results/sst2/checkpoints. Training from scratch.\n",
      "[NeMo I 2022-09-22 16:13:24 exp_manager:194] Experiments will be logged at /workspace/mount/results/sst2\n",
      "Lock 140351380673104 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100% 570/570 [00:00<00:00, 746kB/s]\n",
      "Lock 140351380673104 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140351380179216 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 51.7MB/s]\n",
      "Lock 140351380179216 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140351380552192 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100% 28.0/28.0 [00:00<00:00, 38.6kB/s]\n",
      "Lock 140351380552192 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140351378826960 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100% 466k/466k [00:00<00:00, 59.6MB/s]\n",
      "Lock 140351378826960 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "Lock 140351379333616 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100% 440M/440M [00:04<00:00, 91.4MB/s] \n",
      "Lock 140351379333616 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:120] Read 67349 examples from /workspace/mount/data/SST-2/train.tsv.\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:239] example 0: ['a', 'lifetime']\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:240] subtokens: [CLS] a lifetime [SEP]\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:241] input_ids: 101 1037 6480 102\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:242] segment_ids: 0 0 0 0\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:243] input_mask: 1 1 1 1\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:239] example 1: ['the', 'film', 'jolts', 'the', 'laughs', 'from', 'the', 'audience', '--', 'as', 'if', 'by', 'cattle', 'prod', '.']\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:240] subtokens: [CLS] the film jolt ##s the laughs from the audience - - as if by cattle pro ##d . [SEP]\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:241] input_ids: 101 1996 2143 22538 2015 1996 11680 2013 1996 4378 1011 1011 2004 2065 2011 7125 4013 2094 1012 102\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 16:13:33 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 16:14:14 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-09-22 16:14:14 data_preprocessing:297] Min: 3 |                  Max: 66 |                  Mean: 13.319262349849293 |                  Median: 10.0\n",
      "[NeMo I 2022-09-22 16:14:14 data_preprocessing:303] 75 percentile: 18.00\n",
      "[NeMo I 2022-09-22 16:14:14 data_preprocessing:304] 99 percentile: 44.00\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:120] Read 100 examples from /workspace/mount/data/SST-2/test.tsv.\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:239] example 0: ['not', 'the', 'kind', 'of', 'film', 'that', 'will', 'appeal', 'to', 'a', 'mainstream', 'american', 'audience', ',', 'but', 'there', 'is', 'a', 'certain', 'charm', 'about', 'the', 'film', 'that', 'makes', 'it', 'a', 'suitable', 'entry', 'into', 'the', 'fest', 'circuit', '.']\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:240] subtokens: [CLS] not the kind of film that will appeal to a mainstream american audience , but there is a certain charm about the film that makes it a suitable entry into the fest circuit . [SEP]\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:241] input_ids: 101 2025 1996 2785 1997 2143 2008 2097 5574 2000 1037 7731 2137 4378 1010 2021 2045 2003 1037 3056 11084 2055 1996 2143 2008 3084 2009 1037 7218 4443 2046 1996 17037 4984 1012 102\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:239] example 1: ['it', \"'s\", 'a', 'beautiful', 'madness', '.']\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:240] subtokens: [CLS] it ' s a beautiful madness . [SEP]\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:241] input_ids: 101 2009 1005 1055 1037 3376 12013 1012 102\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 16:14:16 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 16:14:16 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-09-22 16:14:16 data_preprocessing:297] Min: 7 |                  Max: 54 |                  Mean: 25.85 |                  Median: 25.0\n",
      "[NeMo I 2022-09-22 16:14:16 data_preprocessing:303] 75 percentile: 34.00\n",
      "[NeMo I 2022-09-22 16:14:16 data_preprocessing:304] 99 percentile: 52.02\n",
      "[NeMo I 2022-09-22 16:14:16 modelPT:753] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        eps: 1e-08\n",
      "        lr: 2e-05\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2022-09-22 16:14:16 lr_scheduler:617] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7fa600e300d0>\" \n",
      "    will be used during training (effective maximum steps = 2106) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    max_steps: 2106\n",
      "    )\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "[NeMo I 2022-09-22 16:14:18 modelPT:627] No optimizer config provided, therefore no optimizer was created\n",
      "\n",
      "    | Name                                                   | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                             | BertEncoder          | 109 M \n",
      "1   | bert_model.embeddings                                  | BertEmbeddings       | 23.8 M\n",
      "2   | bert_model.embeddings.word_embeddings                  | Embedding            | 23.4 M\n",
      "3   | bert_model.embeddings.position_embeddings              | Embedding            | 393 K \n",
      "4   | bert_model.embeddings.token_type_embeddings            | Embedding            | 1.5 K \n",
      "5   | bert_model.embeddings.LayerNorm                        | LayerNorm            | 1.5 K \n",
      "6   | bert_model.embeddings.dropout                          | Dropout              | 0     \n",
      "7   | bert_model.encoder                                     | BertEncoder          | 85.1 M\n",
      "8   | bert_model.encoder.layer                               | ModuleList           | 85.1 M\n",
      "9   | bert_model.encoder.layer.0                             | BertLayer            | 7.1 M \n",
      "10  | bert_model.encoder.layer.0.attention                   | BertAttention        | 2.4 M \n",
      "11  | bert_model.encoder.layer.0.attention.self              | BertSelfAttention    | 1.8 M \n",
      "12  | bert_model.encoder.layer.0.attention.self.query        | Linear               | 590 K \n",
      "13  | bert_model.encoder.layer.0.attention.self.key          | Linear               | 590 K \n",
      "14  | bert_model.encoder.layer.0.attention.self.value        | Linear               | 590 K \n",
      "15  | bert_model.encoder.layer.0.attention.self.dropout      | Dropout              | 0     \n",
      "16  | bert_model.encoder.layer.0.attention.output            | BertSelfOutput       | 592 K \n",
      "17  | bert_model.encoder.layer.0.attention.output.dense      | Linear               | 590 K \n",
      "18  | bert_model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "19  | bert_model.encoder.layer.0.attention.output.dropout    | Dropout              | 0     \n",
      "20  | bert_model.encoder.layer.0.intermediate                | BertIntermediate     | 2.4 M \n",
      "21  | bert_model.encoder.layer.0.intermediate.dense          | Linear               | 2.4 M \n",
      "22  | bert_model.encoder.layer.0.output                      | BertOutput           | 2.4 M \n",
      "23  | bert_model.encoder.layer.0.output.dense                | Linear               | 2.4 M \n",
      "24  | bert_model.encoder.layer.0.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "25  | bert_model.encoder.layer.0.output.dropout              | Dropout              | 0     \n",
      "26  | bert_model.encoder.layer.1                             | BertLayer            | 7.1 M \n",
      "27  | bert_model.encoder.layer.1.attention                   | BertAttention        | 2.4 M \n",
      "28  | bert_model.encoder.layer.1.attention.self              | BertSelfAttention    | 1.8 M \n",
      "29  | bert_model.encoder.layer.1.attention.self.query        | Linear               | 590 K \n",
      "30  | bert_model.encoder.layer.1.attention.self.key          | Linear               | 590 K \n",
      "31  | bert_model.encoder.layer.1.attention.self.value        | Linear               | 590 K \n",
      "32  | bert_model.encoder.layer.1.attention.self.dropout      | Dropout              | 0     \n",
      "33  | bert_model.encoder.layer.1.attention.output            | BertSelfOutput       | 592 K \n",
      "34  | bert_model.encoder.layer.1.attention.output.dense      | Linear               | 590 K \n",
      "35  | bert_model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "36  | bert_model.encoder.layer.1.attention.output.dropout    | Dropout              | 0     \n",
      "37  | bert_model.encoder.layer.1.intermediate                | BertIntermediate     | 2.4 M \n",
      "38  | bert_model.encoder.layer.1.intermediate.dense          | Linear               | 2.4 M \n",
      "39  | bert_model.encoder.layer.1.output                      | BertOutput           | 2.4 M \n",
      "40  | bert_model.encoder.layer.1.output.dense                | Linear               | 2.4 M \n",
      "41  | bert_model.encoder.layer.1.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "42  | bert_model.encoder.layer.1.output.dropout              | Dropout              | 0     \n",
      "43  | bert_model.encoder.layer.2                             | BertLayer            | 7.1 M \n",
      "44  | bert_model.encoder.layer.2.attention                   | BertAttention        | 2.4 M \n",
      "45  | bert_model.encoder.layer.2.attention.self              | BertSelfAttention    | 1.8 M \n",
      "46  | bert_model.encoder.layer.2.attention.self.query        | Linear               | 590 K \n",
      "47  | bert_model.encoder.layer.2.attention.self.key          | Linear               | 590 K \n",
      "48  | bert_model.encoder.layer.2.attention.self.value        | Linear               | 590 K \n",
      "49  | bert_model.encoder.layer.2.attention.self.dropout      | Dropout              | 0     \n",
      "50  | bert_model.encoder.layer.2.attention.output            | BertSelfOutput       | 592 K \n",
      "51  | bert_model.encoder.layer.2.attention.output.dense      | Linear               | 590 K \n",
      "52  | bert_model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "53  | bert_model.encoder.layer.2.attention.output.dropout    | Dropout              | 0     \n",
      "54  | bert_model.encoder.layer.2.intermediate                | BertIntermediate     | 2.4 M \n",
      "55  | bert_model.encoder.layer.2.intermediate.dense          | Linear               | 2.4 M \n",
      "56  | bert_model.encoder.layer.2.output                      | BertOutput           | 2.4 M \n",
      "57  | bert_model.encoder.layer.2.output.dense                | Linear               | 2.4 M \n",
      "58  | bert_model.encoder.layer.2.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "59  | bert_model.encoder.layer.2.output.dropout              | Dropout              | 0     \n",
      "60  | bert_model.encoder.layer.3                             | BertLayer            | 7.1 M \n",
      "61  | bert_model.encoder.layer.3.attention                   | BertAttention        | 2.4 M \n",
      "62  | bert_model.encoder.layer.3.attention.self              | BertSelfAttention    | 1.8 M \n",
      "63  | bert_model.encoder.layer.3.attention.self.query        | Linear               | 590 K \n",
      "64  | bert_model.encoder.layer.3.attention.self.key          | Linear               | 590 K \n",
      "65  | bert_model.encoder.layer.3.attention.self.value        | Linear               | 590 K \n",
      "66  | bert_model.encoder.layer.3.attention.self.dropout      | Dropout              | 0     \n",
      "67  | bert_model.encoder.layer.3.attention.output            | BertSelfOutput       | 592 K \n",
      "68  | bert_model.encoder.layer.3.attention.output.dense      | Linear               | 590 K \n",
      "69  | bert_model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "70  | bert_model.encoder.layer.3.attention.output.dropout    | Dropout              | 0     \n",
      "71  | bert_model.encoder.layer.3.intermediate                | BertIntermediate     | 2.4 M \n",
      "72  | bert_model.encoder.layer.3.intermediate.dense          | Linear               | 2.4 M \n",
      "73  | bert_model.encoder.layer.3.output                      | BertOutput           | 2.4 M \n",
      "74  | bert_model.encoder.layer.3.output.dense                | Linear               | 2.4 M \n",
      "75  | bert_model.encoder.layer.3.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "76  | bert_model.encoder.layer.3.output.dropout              | Dropout              | 0     \n",
      "77  | bert_model.encoder.layer.4                             | BertLayer            | 7.1 M \n",
      "78  | bert_model.encoder.layer.4.attention                   | BertAttention        | 2.4 M \n",
      "79  | bert_model.encoder.layer.4.attention.self              | BertSelfAttention    | 1.8 M \n",
      "80  | bert_model.encoder.layer.4.attention.self.query        | Linear               | 590 K \n",
      "81  | bert_model.encoder.layer.4.attention.self.key          | Linear               | 590 K \n",
      "82  | bert_model.encoder.layer.4.attention.self.value        | Linear               | 590 K \n",
      "83  | bert_model.encoder.layer.4.attention.self.dropout      | Dropout              | 0     \n",
      "84  | bert_model.encoder.layer.4.attention.output            | BertSelfOutput       | 592 K \n",
      "85  | bert_model.encoder.layer.4.attention.output.dense      | Linear               | 590 K \n",
      "86  | bert_model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "87  | bert_model.encoder.layer.4.attention.output.dropout    | Dropout              | 0     \n",
      "88  | bert_model.encoder.layer.4.intermediate                | BertIntermediate     | 2.4 M \n",
      "89  | bert_model.encoder.layer.4.intermediate.dense          | Linear               | 2.4 M \n",
      "90  | bert_model.encoder.layer.4.output                      | BertOutput           | 2.4 M \n",
      "91  | bert_model.encoder.layer.4.output.dense                | Linear               | 2.4 M \n",
      "92  | bert_model.encoder.layer.4.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "93  | bert_model.encoder.layer.4.output.dropout              | Dropout              | 0     \n",
      "94  | bert_model.encoder.layer.5                             | BertLayer            | 7.1 M \n",
      "95  | bert_model.encoder.layer.5.attention                   | BertAttention        | 2.4 M \n",
      "96  | bert_model.encoder.layer.5.attention.self              | BertSelfAttention    | 1.8 M \n",
      "97  | bert_model.encoder.layer.5.attention.self.query        | Linear               | 590 K \n",
      "98  | bert_model.encoder.layer.5.attention.self.key          | Linear               | 590 K \n",
      "99  | bert_model.encoder.layer.5.attention.self.value        | Linear               | 590 K \n",
      "100 | bert_model.encoder.layer.5.attention.self.dropout      | Dropout              | 0     \n",
      "101 | bert_model.encoder.layer.5.attention.output            | BertSelfOutput       | 592 K \n",
      "102 | bert_model.encoder.layer.5.attention.output.dense      | Linear               | 590 K \n",
      "103 | bert_model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "104 | bert_model.encoder.layer.5.attention.output.dropout    | Dropout              | 0     \n",
      "105 | bert_model.encoder.layer.5.intermediate                | BertIntermediate     | 2.4 M \n",
      "106 | bert_model.encoder.layer.5.intermediate.dense          | Linear               | 2.4 M \n",
      "107 | bert_model.encoder.layer.5.output                      | BertOutput           | 2.4 M \n",
      "108 | bert_model.encoder.layer.5.output.dense                | Linear               | 2.4 M \n",
      "109 | bert_model.encoder.layer.5.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "110 | bert_model.encoder.layer.5.output.dropout              | Dropout              | 0     \n",
      "111 | bert_model.encoder.layer.6                             | BertLayer            | 7.1 M \n",
      "112 | bert_model.encoder.layer.6.attention                   | BertAttention        | 2.4 M \n",
      "113 | bert_model.encoder.layer.6.attention.self              | BertSelfAttention    | 1.8 M \n",
      "114 | bert_model.encoder.layer.6.attention.self.query        | Linear               | 590 K \n",
      "115 | bert_model.encoder.layer.6.attention.self.key          | Linear               | 590 K \n",
      "116 | bert_model.encoder.layer.6.attention.self.value        | Linear               | 590 K \n",
      "117 | bert_model.encoder.layer.6.attention.self.dropout      | Dropout              | 0     \n",
      "118 | bert_model.encoder.layer.6.attention.output            | BertSelfOutput       | 592 K \n",
      "119 | bert_model.encoder.layer.6.attention.output.dense      | Linear               | 590 K \n",
      "120 | bert_model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "121 | bert_model.encoder.layer.6.attention.output.dropout    | Dropout              | 0     \n",
      "122 | bert_model.encoder.layer.6.intermediate                | BertIntermediate     | 2.4 M \n",
      "123 | bert_model.encoder.layer.6.intermediate.dense          | Linear               | 2.4 M \n",
      "124 | bert_model.encoder.layer.6.output                      | BertOutput           | 2.4 M \n",
      "125 | bert_model.encoder.layer.6.output.dense                | Linear               | 2.4 M \n",
      "126 | bert_model.encoder.layer.6.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "127 | bert_model.encoder.layer.6.output.dropout              | Dropout              | 0     \n",
      "128 | bert_model.encoder.layer.7                             | BertLayer            | 7.1 M \n",
      "129 | bert_model.encoder.layer.7.attention                   | BertAttention        | 2.4 M \n",
      "130 | bert_model.encoder.layer.7.attention.self              | BertSelfAttention    | 1.8 M \n",
      "131 | bert_model.encoder.layer.7.attention.self.query        | Linear               | 590 K \n",
      "132 | bert_model.encoder.layer.7.attention.self.key          | Linear               | 590 K \n",
      "133 | bert_model.encoder.layer.7.attention.self.value        | Linear               | 590 K \n",
      "134 | bert_model.encoder.layer.7.attention.self.dropout      | Dropout              | 0     \n",
      "135 | bert_model.encoder.layer.7.attention.output            | BertSelfOutput       | 592 K \n",
      "136 | bert_model.encoder.layer.7.attention.output.dense      | Linear               | 590 K \n",
      "137 | bert_model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "138 | bert_model.encoder.layer.7.attention.output.dropout    | Dropout              | 0     \n",
      "139 | bert_model.encoder.layer.7.intermediate                | BertIntermediate     | 2.4 M \n",
      "140 | bert_model.encoder.layer.7.intermediate.dense          | Linear               | 2.4 M \n",
      "141 | bert_model.encoder.layer.7.output                      | BertOutput           | 2.4 M \n",
      "142 | bert_model.encoder.layer.7.output.dense                | Linear               | 2.4 M \n",
      "143 | bert_model.encoder.layer.7.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "144 | bert_model.encoder.layer.7.output.dropout              | Dropout              | 0     \n",
      "145 | bert_model.encoder.layer.8                             | BertLayer            | 7.1 M \n",
      "146 | bert_model.encoder.layer.8.attention                   | BertAttention        | 2.4 M \n",
      "147 | bert_model.encoder.layer.8.attention.self              | BertSelfAttention    | 1.8 M \n",
      "148 | bert_model.encoder.layer.8.attention.self.query        | Linear               | 590 K \n",
      "149 | bert_model.encoder.layer.8.attention.self.key          | Linear               | 590 K \n",
      "150 | bert_model.encoder.layer.8.attention.self.value        | Linear               | 590 K \n",
      "151 | bert_model.encoder.layer.8.attention.self.dropout      | Dropout              | 0     \n",
      "152 | bert_model.encoder.layer.8.attention.output            | BertSelfOutput       | 592 K \n",
      "153 | bert_model.encoder.layer.8.attention.output.dense      | Linear               | 590 K \n",
      "154 | bert_model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "155 | bert_model.encoder.layer.8.attention.output.dropout    | Dropout              | 0     \n",
      "156 | bert_model.encoder.layer.8.intermediate                | BertIntermediate     | 2.4 M \n",
      "157 | bert_model.encoder.layer.8.intermediate.dense          | Linear               | 2.4 M \n",
      "158 | bert_model.encoder.layer.8.output                      | BertOutput           | 2.4 M \n",
      "159 | bert_model.encoder.layer.8.output.dense                | Linear               | 2.4 M \n",
      "160 | bert_model.encoder.layer.8.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "161 | bert_model.encoder.layer.8.output.dropout              | Dropout              | 0     \n",
      "162 | bert_model.encoder.layer.9                             | BertLayer            | 7.1 M \n",
      "163 | bert_model.encoder.layer.9.attention                   | BertAttention        | 2.4 M \n",
      "164 | bert_model.encoder.layer.9.attention.self              | BertSelfAttention    | 1.8 M \n",
      "165 | bert_model.encoder.layer.9.attention.self.query        | Linear               | 590 K \n",
      "166 | bert_model.encoder.layer.9.attention.self.key          | Linear               | 590 K \n",
      "167 | bert_model.encoder.layer.9.attention.self.value        | Linear               | 590 K \n",
      "168 | bert_model.encoder.layer.9.attention.self.dropout      | Dropout              | 0     \n",
      "169 | bert_model.encoder.layer.9.attention.output            | BertSelfOutput       | 592 K \n",
      "170 | bert_model.encoder.layer.9.attention.output.dense      | Linear               | 590 K \n",
      "171 | bert_model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "172 | bert_model.encoder.layer.9.attention.output.dropout    | Dropout              | 0     \n",
      "173 | bert_model.encoder.layer.9.intermediate                | BertIntermediate     | 2.4 M \n",
      "174 | bert_model.encoder.layer.9.intermediate.dense          | Linear               | 2.4 M \n",
      "175 | bert_model.encoder.layer.9.output                      | BertOutput           | 2.4 M \n",
      "176 | bert_model.encoder.layer.9.output.dense                | Linear               | 2.4 M \n",
      "177 | bert_model.encoder.layer.9.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "178 | bert_model.encoder.layer.9.output.dropout              | Dropout              | 0     \n",
      "179 | bert_model.encoder.layer.10                            | BertLayer            | 7.1 M \n",
      "180 | bert_model.encoder.layer.10.attention                  | BertAttention        | 2.4 M \n",
      "181 | bert_model.encoder.layer.10.attention.self             | BertSelfAttention    | 1.8 M \n",
      "182 | bert_model.encoder.layer.10.attention.self.query       | Linear               | 590 K \n",
      "183 | bert_model.encoder.layer.10.attention.self.key         | Linear               | 590 K \n",
      "184 | bert_model.encoder.layer.10.attention.self.value       | Linear               | 590 K \n",
      "185 | bert_model.encoder.layer.10.attention.self.dropout     | Dropout              | 0     \n",
      "186 | bert_model.encoder.layer.10.attention.output           | BertSelfOutput       | 592 K \n",
      "187 | bert_model.encoder.layer.10.attention.output.dense     | Linear               | 590 K \n",
      "188 | bert_model.encoder.layer.10.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "189 | bert_model.encoder.layer.10.attention.output.dropout   | Dropout              | 0     \n",
      "190 | bert_model.encoder.layer.10.intermediate               | BertIntermediate     | 2.4 M \n",
      "191 | bert_model.encoder.layer.10.intermediate.dense         | Linear               | 2.4 M \n",
      "192 | bert_model.encoder.layer.10.output                     | BertOutput           | 2.4 M \n",
      "193 | bert_model.encoder.layer.10.output.dense               | Linear               | 2.4 M \n",
      "194 | bert_model.encoder.layer.10.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "195 | bert_model.encoder.layer.10.output.dropout             | Dropout              | 0     \n",
      "196 | bert_model.encoder.layer.11                            | BertLayer            | 7.1 M \n",
      "197 | bert_model.encoder.layer.11.attention                  | BertAttention        | 2.4 M \n",
      "198 | bert_model.encoder.layer.11.attention.self             | BertSelfAttention    | 1.8 M \n",
      "199 | bert_model.encoder.layer.11.attention.self.query       | Linear               | 590 K \n",
      "200 | bert_model.encoder.layer.11.attention.self.key         | Linear               | 590 K \n",
      "201 | bert_model.encoder.layer.11.attention.self.value       | Linear               | 590 K \n",
      "202 | bert_model.encoder.layer.11.attention.self.dropout     | Dropout              | 0     \n",
      "203 | bert_model.encoder.layer.11.attention.output           | BertSelfOutput       | 592 K \n",
      "204 | bert_model.encoder.layer.11.attention.output.dense     | Linear               | 590 K \n",
      "205 | bert_model.encoder.layer.11.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "206 | bert_model.encoder.layer.11.attention.output.dropout   | Dropout              | 0     \n",
      "207 | bert_model.encoder.layer.11.intermediate               | BertIntermediate     | 2.4 M \n",
      "208 | bert_model.encoder.layer.11.intermediate.dense         | Linear               | 2.4 M \n",
      "209 | bert_model.encoder.layer.11.output                     | BertOutput           | 2.4 M \n",
      "210 | bert_model.encoder.layer.11.output.dense               | Linear               | 2.4 M \n",
      "211 | bert_model.encoder.layer.11.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "212 | bert_model.encoder.layer.11.output.dropout             | Dropout              | 0     \n",
      "213 | bert_model.pooler                                      | BertPooler           | 590 K \n",
      "214 | bert_model.pooler.dense                                | Linear               | 590 K \n",
      "215 | bert_model.pooler.activation                           | Tanh                 | 0     \n",
      "216 | classifier                                             | SequenceClassifier   | 592 K \n",
      "217 | classifier.dropout                                     | Dropout              | 0     \n",
      "218 | classifier.mlp                                         | MultiLayerPerceptron | 592 K \n",
      "219 | classifier.mlp.layer0                                  | Linear               | 590 K \n",
      "220 | classifier.mlp.layer2                                  | Linear               | 1.5 K \n",
      "221 | loss                                                   | CrossEntropyLoss     | 0     \n",
      "222 | classification_report                                  | ClassificationReport | 0     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "\n",
      "    | Name                                                   | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                             | BertEncoder          | 109 M \n",
      "1   | bert_model.embeddings                                  | BertEmbeddings       | 23.8 M\n",
      "2   | bert_model.embeddings.word_embeddings                  | Embedding            | 23.4 M\n",
      "3   | bert_model.embeddings.position_embeddings              | Embedding            | 393 K \n",
      "4   | bert_model.embeddings.token_type_embeddings            | Embedding            | 1.5 K \n",
      "5   | bert_model.embeddings.LayerNorm                        | LayerNorm            | 1.5 K \n",
      "6   | bert_model.embeddings.dropout                          | Dropout              | 0     \n",
      "7   | bert_model.encoder                                     | BertEncoder          | 85.1 M\n",
      "8   | bert_model.encoder.layer                               | ModuleList           | 85.1 M\n",
      "9   | bert_model.encoder.layer.0                             | BertLayer            | 7.1 M \n",
      "10  | bert_model.encoder.layer.0.attention                   | BertAttention        | 2.4 M \n",
      "11  | bert_model.encoder.layer.0.attention.self              | BertSelfAttention    | 1.8 M \n",
      "12  | bert_model.encoder.layer.0.attention.self.query        | Linear               | 590 K \n",
      "13  | bert_model.encoder.layer.0.attention.self.key          | Linear               | 590 K \n",
      "14  | bert_model.encoder.layer.0.attention.self.value        | Linear               | 590 K \n",
      "15  | bert_model.encoder.layer.0.attention.self.dropout      | Dropout              | 0     \n",
      "16  | bert_model.encoder.layer.0.attention.output            | BertSelfOutput       | 592 K \n",
      "17  | bert_model.encoder.layer.0.attention.output.dense      | Linear               | 590 K \n",
      "18  | bert_model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "19  | bert_model.encoder.layer.0.attention.output.dropout    | Dropout              | 0     \n",
      "20  | bert_model.encoder.layer.0.intermediate                | BertIntermediate     | 2.4 M \n",
      "21  | bert_model.encoder.layer.0.intermediate.dense          | Linear               | 2.4 M \n",
      "22  | bert_model.encoder.layer.0.output                      | BertOutput           | 2.4 M \n",
      "23  | bert_model.encoder.layer.0.output.dense                | Linear               | 2.4 M \n",
      "24  | bert_model.encoder.layer.0.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "25  | bert_model.encoder.layer.0.output.dropout              | Dropout              | 0     \n",
      "26  | bert_model.encoder.layer.1                             | BertLayer            | 7.1 M \n",
      "27  | bert_model.encoder.layer.1.attention                   | BertAttention        | 2.4 M \n",
      "28  | bert_model.encoder.layer.1.attention.self              | BertSelfAttention    | 1.8 M \n",
      "29  | bert_model.encoder.layer.1.attention.self.query        | Linear               | 590 K \n",
      "30  | bert_model.encoder.layer.1.attention.self.key          | Linear               | 590 K \n",
      "31  | bert_model.encoder.layer.1.attention.self.value        | Linear               | 590 K \n",
      "32  | bert_model.encoder.layer.1.attention.self.dropout      | Dropout              | 0     \n",
      "33  | bert_model.encoder.layer.1.attention.output            | BertSelfOutput       | 592 K \n",
      "34  | bert_model.encoder.layer.1.attention.output.dense      | Linear               | 590 K \n",
      "35  | bert_model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "36  | bert_model.encoder.layer.1.attention.output.dropout    | Dropout              | 0     \n",
      "37  | bert_model.encoder.layer.1.intermediate                | BertIntermediate     | 2.4 M \n",
      "38  | bert_model.encoder.layer.1.intermediate.dense          | Linear               | 2.4 M \n",
      "39  | bert_model.encoder.layer.1.output                      | BertOutput           | 2.4 M \n",
      "40  | bert_model.encoder.layer.1.output.dense                | Linear               | 2.4 M \n",
      "41  | bert_model.encoder.layer.1.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "42  | bert_model.encoder.layer.1.output.dropout              | Dropout              | 0     \n",
      "43  | bert_model.encoder.layer.2                             | BertLayer            | 7.1 M \n",
      "44  | bert_model.encoder.layer.2.attention                   | BertAttention        | 2.4 M \n",
      "45  | bert_model.encoder.layer.2.attention.self              | BertSelfAttention    | 1.8 M \n",
      "46  | bert_model.encoder.layer.2.attention.self.query        | Linear               | 590 K \n",
      "47  | bert_model.encoder.layer.2.attention.self.key          | Linear               | 590 K \n",
      "48  | bert_model.encoder.layer.2.attention.self.value        | Linear               | 590 K \n",
      "49  | bert_model.encoder.layer.2.attention.self.dropout      | Dropout              | 0     \n",
      "50  | bert_model.encoder.layer.2.attention.output            | BertSelfOutput       | 592 K \n",
      "51  | bert_model.encoder.layer.2.attention.output.dense      | Linear               | 590 K \n",
      "52  | bert_model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "53  | bert_model.encoder.layer.2.attention.output.dropout    | Dropout              | 0     \n",
      "54  | bert_model.encoder.layer.2.intermediate                | BertIntermediate     | 2.4 M \n",
      "55  | bert_model.encoder.layer.2.intermediate.dense          | Linear               | 2.4 M \n",
      "56  | bert_model.encoder.layer.2.output                      | BertOutput           | 2.4 M \n",
      "57  | bert_model.encoder.layer.2.output.dense                | Linear               | 2.4 M \n",
      "58  | bert_model.encoder.layer.2.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "59  | bert_model.encoder.layer.2.output.dropout              | Dropout              | 0     \n",
      "60  | bert_model.encoder.layer.3                             | BertLayer            | 7.1 M \n",
      "61  | bert_model.encoder.layer.3.attention                   | BertAttention        | 2.4 M \n",
      "62  | bert_model.encoder.layer.3.attention.self              | BertSelfAttention    | 1.8 M \n",
      "63  | bert_model.encoder.layer.3.attention.self.query        | Linear               | 590 K \n",
      "64  | bert_model.encoder.layer.3.attention.self.key          | Linear               | 590 K \n",
      "65  | bert_model.encoder.layer.3.attention.self.value        | Linear               | 590 K \n",
      "66  | bert_model.encoder.layer.3.attention.self.dropout      | Dropout              | 0     \n",
      "67  | bert_model.encoder.layer.3.attention.output            | BertSelfOutput       | 592 K \n",
      "68  | bert_model.encoder.layer.3.attention.output.dense      | Linear               | 590 K \n",
      "69  | bert_model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "70  | bert_model.encoder.layer.3.attention.output.dropout    | Dropout              | 0     \n",
      "71  | bert_model.encoder.layer.3.intermediate                | BertIntermediate     | 2.4 M \n",
      "72  | bert_model.encoder.layer.3.intermediate.dense          | Linear               | 2.4 M \n",
      "73  | bert_model.encoder.layer.3.output                      | BertOutput           | 2.4 M \n",
      "74  | bert_model.encoder.layer.3.output.dense                | Linear               | 2.4 M \n",
      "75  | bert_model.encoder.layer.3.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "76  | bert_model.encoder.layer.3.output.dropout              | Dropout              | 0     \n",
      "77  | bert_model.encoder.layer.4                             | BertLayer            | 7.1 M \n",
      "78  | bert_model.encoder.layer.4.attention                   | BertAttention        | 2.4 M \n",
      "79  | bert_model.encoder.layer.4.attention.self              | BertSelfAttention    | 1.8 M \n",
      "80  | bert_model.encoder.layer.4.attention.self.query        | Linear               | 590 K \n",
      "81  | bert_model.encoder.layer.4.attention.self.key          | Linear               | 590 K \n",
      "82  | bert_model.encoder.layer.4.attention.self.value        | Linear               | 590 K \n",
      "83  | bert_model.encoder.layer.4.attention.self.dropout      | Dropout              | 0     \n",
      "84  | bert_model.encoder.layer.4.attention.output            | BertSelfOutput       | 592 K \n",
      "85  | bert_model.encoder.layer.4.attention.output.dense      | Linear               | 590 K \n",
      "86  | bert_model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "87  | bert_model.encoder.layer.4.attention.output.dropout    | Dropout              | 0     \n",
      "88  | bert_model.encoder.layer.4.intermediate                | BertIntermediate     | 2.4 M \n",
      "89  | bert_model.encoder.layer.4.intermediate.dense          | Linear               | 2.4 M \n",
      "90  | bert_model.encoder.layer.4.output                      | BertOutput           | 2.4 M \n",
      "91  | bert_model.encoder.layer.4.output.dense                | Linear               | 2.4 M \n",
      "92  | bert_model.encoder.layer.4.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "93  | bert_model.encoder.layer.4.output.dropout              | Dropout              | 0     \n",
      "94  | bert_model.encoder.layer.5                             | BertLayer            | 7.1 M \n",
      "95  | bert_model.encoder.layer.5.attention                   | BertAttention        | 2.4 M \n",
      "96  | bert_model.encoder.layer.5.attention.self              | BertSelfAttention    | 1.8 M \n",
      "97  | bert_model.encoder.layer.5.attention.self.query        | Linear               | 590 K \n",
      "98  | bert_model.encoder.layer.5.attention.self.key          | Linear               | 590 K \n",
      "99  | bert_model.encoder.layer.5.attention.self.value        | Linear               | 590 K \n",
      "100 | bert_model.encoder.layer.5.attention.self.dropout      | Dropout              | 0     \n",
      "101 | bert_model.encoder.layer.5.attention.output            | BertSelfOutput       | 592 K \n",
      "102 | bert_model.encoder.layer.5.attention.output.dense      | Linear               | 590 K \n",
      "103 | bert_model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "104 | bert_model.encoder.layer.5.attention.output.dropout    | Dropout              | 0     \n",
      "105 | bert_model.encoder.layer.5.intermediate                | BertIntermediate     | 2.4 M \n",
      "106 | bert_model.encoder.layer.5.intermediate.dense          | Linear               | 2.4 M \n",
      "107 | bert_model.encoder.layer.5.output                      | BertOutput           | 2.4 M \n",
      "108 | bert_model.encoder.layer.5.output.dense                | Linear               | 2.4 M \n",
      "109 | bert_model.encoder.layer.5.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "110 | bert_model.encoder.layer.5.output.dropout              | Dropout              | 0     \n",
      "111 | bert_model.encoder.layer.6                             | BertLayer            | 7.1 M \n",
      "112 | bert_model.encoder.layer.6.attention                   | BertAttention        | 2.4 M \n",
      "113 | bert_model.encoder.layer.6.attention.self              | BertSelfAttention    | 1.8 M \n",
      "114 | bert_model.encoder.layer.6.attention.self.query        | Linear               | 590 K \n",
      "115 | bert_model.encoder.layer.6.attention.self.key          | Linear               | 590 K \n",
      "116 | bert_model.encoder.layer.6.attention.self.value        | Linear               | 590 K \n",
      "117 | bert_model.encoder.layer.6.attention.self.dropout      | Dropout              | 0     \n",
      "118 | bert_model.encoder.layer.6.attention.output            | BertSelfOutput       | 592 K \n",
      "119 | bert_model.encoder.layer.6.attention.output.dense      | Linear               | 590 K \n",
      "120 | bert_model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "121 | bert_model.encoder.layer.6.attention.output.dropout    | Dropout              | 0     \n",
      "122 | bert_model.encoder.layer.6.intermediate                | BertIntermediate     | 2.4 M \n",
      "123 | bert_model.encoder.layer.6.intermediate.dense          | Linear               | 2.4 M \n",
      "124 | bert_model.encoder.layer.6.output                      | BertOutput           | 2.4 M \n",
      "125 | bert_model.encoder.layer.6.output.dense                | Linear               | 2.4 M \n",
      "126 | bert_model.encoder.layer.6.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "127 | bert_model.encoder.layer.6.output.dropout              | Dropout              | 0     \n",
      "128 | bert_model.encoder.layer.7                             | BertLayer            | 7.1 M \n",
      "129 | bert_model.encoder.layer.7.attention                   | BertAttention        | 2.4 M \n",
      "130 | bert_model.encoder.layer.7.attention.self              | BertSelfAttention    | 1.8 M \n",
      "131 | bert_model.encoder.layer.7.attention.self.query        | Linear               | 590 K \n",
      "132 | bert_model.encoder.layer.7.attention.self.key          | Linear               | 590 K \n",
      "133 | bert_model.encoder.layer.7.attention.self.value        | Linear               | 590 K \n",
      "134 | bert_model.encoder.layer.7.attention.self.dropout      | Dropout              | 0     \n",
      "135 | bert_model.encoder.layer.7.attention.output            | BertSelfOutput       | 592 K \n",
      "136 | bert_model.encoder.layer.7.attention.output.dense      | Linear               | 590 K \n",
      "137 | bert_model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "138 | bert_model.encoder.layer.7.attention.output.dropout    | Dropout              | 0     \n",
      "139 | bert_model.encoder.layer.7.intermediate                | BertIntermediate     | 2.4 M \n",
      "140 | bert_model.encoder.layer.7.intermediate.dense          | Linear               | 2.4 M \n",
      "141 | bert_model.encoder.layer.7.output                      | BertOutput           | 2.4 M \n",
      "142 | bert_model.encoder.layer.7.output.dense                | Linear               | 2.4 M \n",
      "143 | bert_model.encoder.layer.7.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "144 | bert_model.encoder.layer.7.output.dropout              | Dropout              | 0     \n",
      "145 | bert_model.encoder.layer.8                             | BertLayer            | 7.1 M \n",
      "146 | bert_model.encoder.layer.8.attention                   | BertAttention        | 2.4 M \n",
      "147 | bert_model.encoder.layer.8.attention.self              | BertSelfAttention    | 1.8 M \n",
      "148 | bert_model.encoder.layer.8.attention.self.query        | Linear               | 590 K \n",
      "149 | bert_model.encoder.layer.8.attention.self.key          | Linear               | 590 K \n",
      "150 | bert_model.encoder.layer.8.attention.self.value        | Linear               | 590 K \n",
      "151 | bert_model.encoder.layer.8.attention.self.dropout      | Dropout              | 0     \n",
      "152 | bert_model.encoder.layer.8.attention.output            | BertSelfOutput       | 592 K \n",
      "153 | bert_model.encoder.layer.8.attention.output.dense      | Linear               | 590 K \n",
      "154 | bert_model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "155 | bert_model.encoder.layer.8.attention.output.dropout    | Dropout              | 0     \n",
      "156 | bert_model.encoder.layer.8.intermediate                | BertIntermediate     | 2.4 M \n",
      "157 | bert_model.encoder.layer.8.intermediate.dense          | Linear               | 2.4 M \n",
      "158 | bert_model.encoder.layer.8.output                      | BertOutput           | 2.4 M \n",
      "159 | bert_model.encoder.layer.8.output.dense                | Linear               | 2.4 M \n",
      "160 | bert_model.encoder.layer.8.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "161 | bert_model.encoder.layer.8.output.dropout              | Dropout              | 0     \n",
      "162 | bert_model.encoder.layer.9                             | BertLayer            | 7.1 M \n",
      "163 | bert_model.encoder.layer.9.attention                   | BertAttention        | 2.4 M \n",
      "164 | bert_model.encoder.layer.9.attention.self              | BertSelfAttention    | 1.8 M \n",
      "165 | bert_model.encoder.layer.9.attention.self.query        | Linear               | 590 K \n",
      "166 | bert_model.encoder.layer.9.attention.self.key          | Linear               | 590 K \n",
      "167 | bert_model.encoder.layer.9.attention.self.value        | Linear               | 590 K \n",
      "168 | bert_model.encoder.layer.9.attention.self.dropout      | Dropout              | 0     \n",
      "169 | bert_model.encoder.layer.9.attention.output            | BertSelfOutput       | 592 K \n",
      "170 | bert_model.encoder.layer.9.attention.output.dense      | Linear               | 590 K \n",
      "171 | bert_model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "172 | bert_model.encoder.layer.9.attention.output.dropout    | Dropout              | 0     \n",
      "173 | bert_model.encoder.layer.9.intermediate                | BertIntermediate     | 2.4 M \n",
      "174 | bert_model.encoder.layer.9.intermediate.dense          | Linear               | 2.4 M \n",
      "175 | bert_model.encoder.layer.9.output                      | BertOutput           | 2.4 M \n",
      "176 | bert_model.encoder.layer.9.output.dense                | Linear               | 2.4 M \n",
      "177 | bert_model.encoder.layer.9.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "178 | bert_model.encoder.layer.9.output.dropout              | Dropout              | 0     \n",
      "179 | bert_model.encoder.layer.10                            | BertLayer            | 7.1 M \n",
      "180 | bert_model.encoder.layer.10.attention                  | BertAttention        | 2.4 M \n",
      "181 | bert_model.encoder.layer.10.attention.self             | BertSelfAttention    | 1.8 M \n",
      "182 | bert_model.encoder.layer.10.attention.self.query       | Linear               | 590 K \n",
      "183 | bert_model.encoder.layer.10.attention.self.key         | Linear               | 590 K \n",
      "184 | bert_model.encoder.layer.10.attention.self.value       | Linear               | 590 K \n",
      "185 | bert_model.encoder.layer.10.attention.self.dropout     | Dropout              | 0     \n",
      "186 | bert_model.encoder.layer.10.attention.output           | BertSelfOutput       | 592 K \n",
      "187 | bert_model.encoder.layer.10.attention.output.dense     | Linear               | 590 K \n",
      "188 | bert_model.encoder.layer.10.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "189 | bert_model.encoder.layer.10.attention.output.dropout   | Dropout              | 0     \n",
      "190 | bert_model.encoder.layer.10.intermediate               | BertIntermediate     | 2.4 M \n",
      "191 | bert_model.encoder.layer.10.intermediate.dense         | Linear               | 2.4 M \n",
      "192 | bert_model.encoder.layer.10.output                     | BertOutput           | 2.4 M \n",
      "193 | bert_model.encoder.layer.10.output.dense               | Linear               | 2.4 M \n",
      "194 | bert_model.encoder.layer.10.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "195 | bert_model.encoder.layer.10.output.dropout             | Dropout              | 0     \n",
      "196 | bert_model.encoder.layer.11                            | BertLayer            | 7.1 M \n",
      "197 | bert_model.encoder.layer.11.attention                  | BertAttention        | 2.4 M \n",
      "198 | bert_model.encoder.layer.11.attention.self             | BertSelfAttention    | 1.8 M \n",
      "199 | bert_model.encoder.layer.11.attention.self.query       | Linear               | 590 K \n",
      "200 | bert_model.encoder.layer.11.attention.self.key         | Linear               | 590 K \n",
      "201 | bert_model.encoder.layer.11.attention.self.value       | Linear               | 590 K \n",
      "202 | bert_model.encoder.layer.11.attention.self.dropout     | Dropout              | 0     \n",
      "203 | bert_model.encoder.layer.11.attention.output           | BertSelfOutput       | 592 K \n",
      "204 | bert_model.encoder.layer.11.attention.output.dense     | Linear               | 590 K \n",
      "205 | bert_model.encoder.layer.11.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "206 | bert_model.encoder.layer.11.attention.output.dropout   | Dropout              | 0     \n",
      "207 | bert_model.encoder.layer.11.intermediate               | BertIntermediate     | 2.4 M \n",
      "208 | bert_model.encoder.layer.11.intermediate.dense         | Linear               | 2.4 M \n",
      "209 | bert_model.encoder.layer.11.output                     | BertOutput           | 2.4 M \n",
      "210 | bert_model.encoder.layer.11.output.dense               | Linear               | 2.4 M \n",
      "211 | bert_model.encoder.layer.11.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "212 | bert_model.encoder.layer.11.output.dropout             | Dropout              | 0     \n",
      "213 | bert_model.pooler                                      | BertPooler           | 590 K \n",
      "214 | bert_model.pooler.dense                                | Linear               | 590 K \n",
      "215 | bert_model.pooler.activation                           | Tanh                 | 0     \n",
      "216 | classifier                                             | SequenceClassifier   | 592 K \n",
      "217 | classifier.dropout                                     | Dropout              | 0     \n",
      "218 | classifier.mlp                                         | MultiLayerPerceptron | 592 K \n",
      "219 | classifier.mlp.layer0                                  | Linear               | 590 K \n",
      "220 | classifier.mlp.layer2                                  | Linear               | 1.5 K \n",
      "221 | loss                                                   | CrossEntropyLoss     | 0     \n",
      "222 | classification_report                                  | ClassificationReport | 0     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "Validation sanity check:  50% 1/2 [00:00<00:00,  1.22it/s][NeMo I 2022-09-22 16:14:19 text_classification_model:166] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             76.47      27.08      40.00         48\n",
      "    label_id: 1                                             57.83      92.31      71.11         52\n",
      "    -------------------\n",
      "    micro avg                                               61.00      61.00      61.00        100\n",
      "    macro avg                                               67.15      59.70      55.56        100\n",
      "    weighted avg                                            66.78      61.00      56.18        100\n",
      "    \n",
      "Epoch 0: 100% 1053/1055 [03:34<00:00,  4.90it/s, loss=0.218, val_loss=0.686, lr=1.11e-5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100% 1055/1055 [03:35<00:00,  4.91it/s, loss=0.218, val_loss=0.686, lr=1.11e-5][NeMo I 2022-09-22 16:17:55 text_classification_model:166] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                            100.00      81.25      89.66         48\n",
      "    label_id: 1                                             85.25     100.00      92.04         52\n",
      "    -------------------\n",
      "    micro avg                                               91.00      91.00      91.00        100\n",
      "    macro avg                                               92.62      90.62      90.85        100\n",
      "    weighted avg                                            92.33      91.00      90.89        100\n",
      "    \n",
      "Epoch 0: 100% 1055/1055 [03:35<00:00,  4.90it/s, loss=0.218, val_loss=0.245, lr=1.11e-5]\n",
      "                                             \u001b[AEpoch 0, global step 1052: val_loss reached 0.24504 (best 0.24504), saving model to \"/workspace/mount/results/sst2/checkpoints/trained-model---val_loss=0.25-epoch=0.ckpt\" as top 3\n",
      "Epoch 0, global step 1052: val_loss reached 0.24504 (best 0.24504), saving model to \"/workspace/mount/results/sst2/checkpoints/trained-model---val_loss=0.25-epoch=0.ckpt\" as top 3\n",
      "Epoch 1: 100% 1053/1055 [03:36<00:00,  4.86it/s, loss=0.148, val_loss=0.245, lr=2.11e-8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100% 1055/1055 [03:36<00:00,  4.87it/s, loss=0.148, val_loss=0.245, lr=2.11e-8][NeMo I 2022-09-22 16:21:56 text_classification_model:166] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             97.50      81.25      88.64         48\n",
      "    label_id: 1                                             85.00      98.08      91.07         52\n",
      "    -------------------\n",
      "    micro avg                                               90.00      90.00      90.00        100\n",
      "    macro avg                                               91.25      89.66      89.85        100\n",
      "    weighted avg                                            91.00      90.00      89.90        100\n",
      "    \n",
      "Epoch 1: 100% 1055/1055 [03:36<00:00,  4.86it/s, loss=0.148, val_loss=0.245, lr=1.05e-8]\n",
      "                                             \u001b[AEpoch 1, global step 2105: val_loss reached 0.24520 (best 0.24504), saving model to \"/workspace/mount/results/sst2/checkpoints/trained-model---val_loss=0.25-epoch=1.ckpt\" as top 3\n",
      "Epoch 1, global step 2105: val_loss reached 0.24520 (best 0.24504), saving model to \"/workspace/mount/results/sst2/checkpoints/trained-model---val_loss=0.25-epoch=1.ckpt\" as top 3\n",
      "Epoch 1: 100% 1055/1055 [03:47<00:00,  4.64it/s, loss=0.148, val_loss=0.245, lr=1.05e-8]Saving latest checkpoint...\n",
      "Saving latest checkpoint...\n",
      "Epoch 1: 100% 1055/1055 [04:05<00:00,  4.29it/s, loss=0.148, val_loss=0.245, lr=1.05e-8]\n",
      "[NeMo I 2022-09-22 16:22:46 train:128] Experiment logs saved to '/workspace/mount/results/sst2'\n",
      "[NeMo I 2022-09-22 16:22:46 train:129] Trained model saved to '/workspace/mount/results/sst2/checkpoints/trained-model.tlt'\n",
      "2022-09-22 16:22:48,406 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n",
      "CPU times: user 9.32 s, sys: 2.26 s, total: 11.6 s\n",
      "Wall time: 9min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# For BERT training on SST-2:\n",
    "!tao text_classification train \\\n",
    "    -e $SPECS_DIR/text_classification/train.yaml \\\n",
    "    -g 1  \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2 \\\n",
    "    training_ds.file_path=$DATA_DIR/SST-2/train.tsv \\\n",
    "    validation_ds.file_path=$DATA_DIR/SST-2/test.tsv \\\n",
    "    model.class_labels.class_labels_file=$DATA_DIR/SST-2/label_ids.csv \\\n",
    "    trainer.amp_level=\"O1\" \\\n",
    "    trainer.precision=16 \\\n",
    "    trainer.max_epochs=2 \\\n",
    "    2>&1|tee my_assessment/step2.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train command produces a model file called `trained-model.tlt` saved at `results/sst2/checkpoints/trained-model.tlt`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 3: Infer and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/mount/data\n"
     ]
    }
   ],
   "source": [
    "!echo $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Queries (not graded)\n",
    "Execute the following cell to create queries for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /dli/task/tao/specs/text_classification/infer.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SOURCE_MOUNT/specs/text_classification/infer.yaml\n",
    "\n",
    "# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.\n",
    "# TAO Spec file for inference using a previously pretrained BERT model for a text classification task.\n",
    "\n",
    "# \"Simulate\" user input: batch with four samples.\n",
    "input_batch:\n",
    "- \"this is a good script , good dialogue , funny even for adults .\"\n",
    "- \"the affectionate loopiness that once seemed congenital to demme s perspective has a tough time emerging from between the badly dated cutesy-pie mystery scenario a nd the newfangled hollywood post-production effects .\"\n",
    "- \" this piece of channel 5 grade trash is , quite frankly , an insult to the intelligence of the true genre enthusiast . \"\n",
    "- \"a delightful coming-of-age story .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on the Trained Model (not graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 14:56:33,707 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 14:56:33,828 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 14:56:37 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-09-22 14:56:41 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-09-22 14:56:41 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/sst2/checkpoints/trained-model.tlt\n",
      "    exp_manager:\n",
      "      task_name: infer\n",
      "      explicit_log_dir: /workspace/mount/results/sst2/infer\n",
      "    input_batch:\n",
      "    - this is a good script , good dialogue , funny even for adults .\n",
      "    - the affectionate loopiness that once seemed congenital to demme s perspective has\n",
      "      a tough time emerging from between the badly dated cutesy-pie mystery scenario a\n",
      "      nd the newfangled hollywood post-production effects .\n",
      "    - ' this piece of channel 5 grade trash is , quite frankly , an insult to the intelligence\n",
      "      of the true genre enthusiast . '\n",
      "    - a delightful coming-of-age story .\n",
      "    encryption_key: '*********'\n",
      "    \n",
      "[NeMo W 2022-09-22 14:56:43 modelPT:193] Using /tmp/tmpaqq08kby/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 139878670092464 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 640kB/s]\n",
      "Lock 139878670092464 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 139878669909536 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 58.7MB/s]\n",
      "Lock 139878669909536 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 139878669909680 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 31.3kB/s]\n",
      "Lock 139878669909680 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 139878670093904 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 72.8MB/s]\n",
      "Lock 139878670093904 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-09-22 14:56:44 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 139878670092080 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:05<00:00, 85.8MB/s]\n",
      "Lock 139878670092080 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo W 2022-09-22 14:56:52 modelPT:193] Using /tmp/tmpaqq08kby/label_ids.csv instead of /workspace/mount/data/SST-2/label_ids.csv.\n",
      "[NeMo I 2022-09-22 14:57:00 infer:103] The prediction results of some sample queries with the trained model:\n",
      "[NeMo I 2022-09-22 14:57:00 infer:105] Query: this is a good script , good dialogue , funny even for adults .\n",
      "[NeMo I 2022-09-22 14:57:00 infer:106] Predicted label: positive\n",
      "[NeMo I 2022-09-22 14:57:00 infer:105] Query: the affectionate loopiness that once seemed congenital to demme s perspective has a tough time emerging from between the badly dated cutesy-pie mystery scenario a nd the newfangled hollywood post-production effects .\n",
      "[NeMo I 2022-09-22 14:57:00 infer:106] Predicted label: negative\n",
      "[NeMo I 2022-09-22 14:57:00 infer:105] Query:  this piece of channel 5 grade trash is , quite frankly , an insult to the intelligence of the true genre enthusiast . \n",
      "[NeMo I 2022-09-22 14:57:00 infer:106] Predicted label: negative\n",
      "[NeMo I 2022-09-22 14:57:00 infer:105] Query: a delightful coming-of-age story .\n",
      "[NeMo I 2022-09-22 14:57:00 infer:106] Predicted label: positive\n",
      "[NeMo I 2022-09-22 14:57:00 infer:109] Experiment logs saved to '/workspace/mount/results/sst2/infer'\n",
      "2022-09-22 14:57:01,989 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# Run inference on user data:\n",
    "!tao text_classification infer \\\n",
    "    -e $SPECS_DIR/text_classification/infer.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your Model (results graded)\n",
    "Execute the following cell without changes.  Review your output to see if you had an F1 result above the 88% goal.  If not, you may need to retrain your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 14:57:03,683 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 14:57:03,796 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 14:57:07 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-09-22 14:57:10 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-09-22 14:57:11 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/sst2/checkpoints/trained-model.tlt\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/sst2/eval\n",
      "      exp_dir: null\n",
      "      name: null\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: false\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: false\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .nemo\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 1000\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 32\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: O2\n",
      "    test_ds:\n",
      "      file_path: /workspace/mount/data/SST-2/test.tsv\n",
      "      batch_size: 32\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "      num_workers: 3\n",
      "      drop_last: false\n",
      "      pin_memory: false\n",
      "    encryption_key: '****'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-09-22 14:57:11 exp_manager:194] Experiments will be logged at /workspace/mount/results/sst2/eval\n",
      "[NeMo W 2022-09-22 14:57:13 modelPT:193] Using /tmp/tmp1b0ypwn1/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140169002973312 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100% 570/570 [00:00<00:00, 723kB/s]\n",
      "Lock 140169002973312 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140169002974320 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 61.3MB/s]\n",
      "Lock 140169002974320 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140169002992832 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100% 28.0/28.0 [00:00<00:00, 30.6kB/s]\n",
      "Lock 140169002992832 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140169006247696 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100% 466k/466k [00:00<00:00, 61.4MB/s]\n",
      "Lock 140169006247696 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-09-22 14:57:13 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140169004424160 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100% 440M/440M [00:05<00:00, 84.6MB/s] \n",
      "Lock 140169004424160 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo W 2022-09-22 14:57:22 modelPT:193] Using /tmp/tmp1b0ypwn1/label_ids.csv instead of /workspace/mount/data/SST-2/label_ids.csv.\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:120] Read 100 examples from /workspace/mount/data/SST-2/test.tsv.\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:239] example 0: ['not', 'the', 'kind', 'of', 'film', 'that', 'will', 'appeal', 'to', 'a', 'mainstream', 'american', 'audience', ',', 'but', 'there', 'is', 'a', 'certain', 'charm', 'about', 'the', 'film', 'that', 'makes', 'it', 'a', 'suitable', 'entry', 'into', 'the', 'fest', 'circuit', '.']\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:240] subtokens: [CLS] not the kind of film that will appeal to a mainstream american audience , but there is a certain charm about the film that makes it a suitable entry into the fest circuit . [SEP]\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:241] input_ids: 101 2025 1996 2785 1997 2143 2008 2097 5574 2000 1037 7731 2137 4378 1010 2021 2045 2003 1037 3056 11084 2055 1996 2143 2008 3084 2009 1037 7218 4443 2046 1996 17037 4984 1012 102\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:239] example 1: ['it', \"'s\", 'a', 'beautiful', 'madness', '.']\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:240] subtokens: [CLS] it ' s a beautiful madness . [SEP]\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:241] input_ids: 101 2009 1005 1055 1037 3376 12013 1012 102\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 14:57:29 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 14:57:29 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-09-22 14:57:29 data_preprocessing:297] Min: 7 |                  Max: 54 |                  Mean: 25.85 |                  Median: 25.0\n",
      "[NeMo I 2022-09-22 14:57:29 data_preprocessing:303] 75 percentile: 34.00\n",
      "[NeMo I 2022-09-22 14:57:29 data_preprocessing:304] 99 percentile: 52.02\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Testing: 100% 4/4 [00:01<00:00,  2.07it/s][NeMo I 2022-09-22 14:57:30 text_classification_model:166] test_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             97.44      79.17      87.36         48\n",
      "    label_id: 1                                             83.61      98.08      90.27         52\n",
      "    -------------------\n",
      "    micro avg                                               89.00      89.00      89.00        100\n",
      "    macro avg                                               90.52      88.62      88.81        100\n",
      "    weighted avg                                            90.24      89.00      88.87        100\n",
      "    \n",
      "Testing: 100% 4/4 [00:01<00:00,  3.31it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_f1': tensor(89., device='cuda:0'),\n",
      " 'test_loss': tensor(0.2312, device='cuda:0'),\n",
      " 'test_precision': tensor(89., device='cuda:0'),\n",
      " 'test_recall': tensor(89., device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "[NeMo I 2022-09-22 14:57:30 evaluate:97] Experiment logs saved to '/workspace/mount/results/sst2/eval'\n",
      "2022-09-22 14:57:31,760 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# For BERT evaluation on SST-2:\n",
    "!tao text_classification evaluate \\\n",
    "    -e $SPECS_DIR/text_classification/evaluate.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/eval \\\n",
    "    test_ds.file_path=$DATA_DIR/SST-2/test.tsv \\\n",
    "    test_ds.batch_size=32 \\\n",
    "    test_ds.num_samples=-1 \\\n",
    "    2>&1|tee my_assessment/step3.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4: Export Custom Model\n",
    "### Export the Model for Riva (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 16:24:20,125 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 16:24:20,265 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 16:24:24 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-09-22 16:24:28 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-09-22 16:24:28 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/sst2/checkpoints/trained-model.tlt\n",
      "    export_to: tc-model.riva\n",
      "    export_format: RIVA\n",
      "    exp_manager:\n",
      "      task_name: export\n",
      "      explicit_log_dir: /workspace/mount/results/sst2/export/\n",
      "    encryption_key: '***'\n",
      "    \n",
      "[NeMo W 2022-09-22 16:24:30 modelPT:193] Using /tmp/tmpwky295_6/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140456742260304 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100% 570/570 [00:00<00:00, 577kB/s]\n",
      "Lock 140456742260304 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140456742258336 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 70.2MB/s]\n",
      "Lock 140456742258336 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140456742273712 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100% 28.0/28.0 [00:00<00:00, 40.3kB/s]\n",
      "Lock 140456742273712 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140456742257136 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100% 466k/466k [00:00<00:00, 67.4MB/s]\n",
      "Lock 140456742257136 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-09-22 16:24:30 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140456742257184 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100% 440M/440M [00:05<00:00, 83.0MB/s] \n",
      "Lock 140456742257184 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo W 2022-09-22 16:24:39 modelPT:193] Using /tmp/tmpwky295_6/label_ids.csv instead of /workspace/mount/data/SST-2/label_ids.csv.\n",
      "[NeMo I 2022-09-22 16:24:45 export:54] Model restored from '/workspace/mount/results/sst2/checkpoints/trained-model.tlt'\n",
      "Could not retrieve the artifact tokenizer.vocab_file used in tokenizer.vocab_file\n",
      "Could not retrieve the artifact label_ids.csv used in class_labels\n",
      "[NeMo I 2022-09-22 16:25:10 export:77] Experiment logs saved to '/workspace/mount/results/sst2/export'\n",
      "[NeMo I 2022-09-22 16:25:10 export:78] Exported model to '/workspace/mount/results/sst2/export/tc-model.riva'\n",
      "[NeMo I 2022-09-22 16:25:11 export:89] Exported model is compliant with Riva\n",
      "2022-09-22 16:25:12,862 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "#  For export to Riva:\n",
    "!tao text_classification export \\\n",
    "    -e $SPECS_DIR/text_classification/export.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/export/ \\\n",
    "    export_format=RIVA \\\n",
    "    export_to=tc-model.riva \\\n",
    "    2>&1|tee my_assessment/step4.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export.log  tc-model.riva\n"
     ]
    }
   ],
   "source": [
    "# Check your work - does the exported tc-model.riva model exist?\n",
    "!ls $EXPORT_MODEL_LOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 5: Build and Deploy with Riva\n",
    "### Set up Project Paths (not graded)\n",
    "This block is complete, but feel free to add to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Riva paths for the project\n",
    "WORKSPACE = \"/dli/task\"\n",
    "\n",
    "##### Riva Paths\n",
    "# ServiceMaker Docker\n",
    "RIVA_SM_CONTAINER = \"nvcr.io/nvidia/riva/riva-speech:1.4.0-beta-servicemaker\"\n",
    "\n",
    "# Model output directories\n",
    "RMIR_LOC = WORKSPACE + \"/riva/riva_quickstart/models_repo_assessment/rmir\"\n",
    "RIVA_MODEL_LOC = WORKSPACE + '/riva/riva_quickstart/models_repo_assessment'\n",
    "\n",
    "# Model Names\n",
    "EXPORT_MODEL_NAME = \"tc-model.riva\"  \n",
    "RMIR_MODEL_NAME = \"tc-model.rmir\"\n",
    "\n",
    "# Riva Quick Start \n",
    "RIVA_QS = WORKSPACE + \"/riva/riva_quickstart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Deploy with Riva ServiceMaker (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release devel (build 22382700)\n",
      "\n",
      "Copyright (c) 2018-2021, NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\n",
      "NVIDIA modifications are covered by the license terms that apply to the underlying\n",
      "project or file.\n",
      "\n",
      "NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for the inference server.  NVIDIA recommends the use of the following flags:\n",
      "   nvidia-docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "2022-09-22 14:59:30,770 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 14:59:30,838 [INFO] Packing binaries for self\n",
      "2022-09-22 14:59:32,030 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 14:59:32,094 [INFO] Trying to extract from model tc-model.riva\n",
      "2022-09-22 14:59:33,348 [INFO] Packing binaries for language_model\n",
      "2022-09-22 14:59:34,543 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 14:59:34,607 [INFO] Trying to extract from model tc-model.riva\n",
      "2022-09-22 14:59:40,834 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 14:59:40,897 [INFO] Trying to extract from model tc-model.riva\n",
      "2022-09-22 14:59:42,155 [INFO] Packing binaries for tokenizer\n",
      "2022-09-22 14:59:43,354 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 14:59:43,418 [INFO] Trying to extract from model tc-model.riva\n"
     ]
    }
   ],
   "source": [
    "# Syntax: riva-build <task-name> output-dir-for-rmir/model.rmir:key dir-for-riva/model.riva:key\n",
    "!docker run --rm --gpus 1 \\\n",
    "    -v $EXPORT_MODEL_LOC:/tao \\\n",
    "    -v $RMIR_LOC:/riva \\\n",
    "    $RIVA_SM_CONTAINER -- \\\n",
    "    riva-build text_classification -f /riva/$RMIR_MODEL_NAME:$KEY /tao/$EXPORT_MODEL_NAME:$KEY \\\n",
    "    2>&1|tee my_assessment/step5.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tc-model.rmir\n"
     ]
    }
   ],
   "source": [
    "# Check your work - does the exported tc-model.rmir model exist?\n",
    "!ls $RMIR_LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release devel (build 22382700)\n",
      "\n",
      "Copyright (c) 2018-2021, NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\n",
      "NVIDIA modifications are covered by the license terms that apply to the underlying\n",
      "project or file.\n",
      "\n",
      "NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for the inference server.  NVIDIA recommends the use of the following flags:\n",
      "   nvidia-docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "2022-09-22 15:00:24,184 [INFO] Writing Riva model repository to '/data/models/'...\n",
      "2022-09-22 15:00:24,184 [INFO] The riva model repo target directory is /data/models/\n",
      "2022-09-22 15:00:25,390 [INFO] Extract_binaries for tokenizer -> /data/models/riva_tokenizer/1\n",
      "2022-09-22 15:00:25,392 [INFO] Extract_binaries for language_model -> /data/models/riva-trt-riva_text_classification_default-nn-bert-base-uncased/1\n",
      "2022-09-22 15:00:29,579 [INFO] Printing copied artifacts:\n",
      "2022-09-22 15:00:29,579 [INFO] {'ckpt': '/data/models/riva-trt-riva_text_classification_default-nn-bert-base-uncased/1/model_weights.ckpt', 'bert_config_file': '/data/models/riva-trt-riva_text_classification_default-nn-bert-base-uncased/1/bert-base-uncased_encoder_config.json'}\n",
      "2022-09-22 15:00:29,579 [INFO] Building TRT engine from PyTorch Checkpoint\n",
      "2022-09-22 15:02:01,277 [INFO] Text Classification classes:2\n",
      "2022-09-22 15:02:01,278 [INFO] Extract_binaries for self -> /data/models/riva_text_classification_default/1\n"
     ]
    }
   ],
   "source": [
    "# Syntax: riva-deploy -f dir-for-rmir/model.rmir:key output-dir-for-repository\n",
    "!docker run --rm --gpus 1 \\\n",
    "    -v $RIVA_MODEL_LOC:/data \\\n",
    "    $RIVA_SM_CONTAINER -- \\\n",
    "    riva-deploy -f /data/rmir/tc-model.rmir:$KEY \\\n",
    "    /data/models/ \\\n",
    "    2>&1|tee -a my_assessment/step5.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riva-trt-riva_text_classification_default-nn-bert-base-uncased\triva_tokenizer\n",
      "riva_text_classification_default\n"
     ]
    }
   ],
   "source": [
    "# Check your work - are there optimized models for text classification?\n",
    "!ls $RIVA_MODEL_LOC/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/riva/riva_quickstart/models_repo_assessment\n"
     ]
    }
   ],
   "source": [
    "!echo $RIVA_MODEL_LOC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 6: Start Riva Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Start Riva (graded)\n",
    "Next, modify the [config.sh](riva/riva_quickstart/config.sh) to enable relevant Riva services. \n",
    "In this case, we want to start NLP services, provide the encryption key, and update the path to the model repository (`RIVA_MODEL_LOC`). \n",
    "Open the [config.sh](riva/riva_quickstart/config.sh) and make changes where necessary, then start the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Riva Speech Services. This may take several minutes depending on the number of models deployed.\n",
      "Waiting for Riva server to load all models...retrying in 10 seconds\n",
      "Waiting for Riva server to load all models...retrying in 10 seconds\n",
      "Riva server is ready...\n"
     ]
    }
   ],
   "source": [
    "# Run Riva Start. This will deploy the model.\n",
    "!cd $RIVA_QS && bash riva_start.sh config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release 21.07 (build 25292380)\n",
      "\n",
      "Copyright (c) 2018-2021, NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\n",
      "NVIDIA modifications are covered by the license terms that apply to the underlying\n",
      "project or file.\n",
      "\n",
      "NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for the inference server.  NVIDIA recommends the use of the following flags:\n",
      "   nvidia-docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "I0922 15:03:55.518829 74 metrics.cc:228] Collecting metrics for GPU 0: Tesla T4\n",
      "I0922 15:03:55.568267 74 onnxruntime.cc:1722] TRITONBACKEND_Initialize: onnxruntime\n",
      "I0922 15:03:55.569107 74 onnxruntime.cc:1732] Triton TRITONBACKEND API version: 1.0\n",
      "I0922 15:03:55.569128 74 onnxruntime.cc:1738] 'onnxruntime' TRITONBACKEND API version: 1.0\n",
      "I0922 15:03:55.805636 74 pinned_memory_manager.cc:206] Pinned memory pool is created at '0x7f3f34000000' with size 268435456\n",
      "I0922 15:03:55.806832 74 cuda_memory_manager.cc:103] CUDA memory pool is created on device 0 with size 1000000000\n",
      "I0922 15:03:55.816749 74 model_repository_manager.cc:1066] loading: riva_tokenizer:1\n",
      "I0922 15:03:55.917069 74 model_repository_manager.cc:1066] loading: riva-trt-riva_text_classification_default-nn-bert-base-uncased:1\n",
      "I0922 15:03:55.917353 74 custom_backend.cc:198] Creating instance riva_tokenizer_0_0_cpu on CPU using libtriton_riva_nlp_tokenizer.so\n",
      "I0922 15:03:55.979630 74 model_repository_manager.cc:1240] successfully loaded 'riva_tokenizer' version 1\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "I0922 15:04:12.057006 74 plan_backend.cc:384] Creating instance riva-trt-riva_text_classification_default-nn-bert-base-uncased_0_0_gpu0 on GPU 0 (7.5) using model.plan\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "I0922 15:04:13.468886 74 plan_backend.cc:768] Created instance riva-trt-riva_text_classification_default-nn-bert-base-uncased_0_0_gpu0 on GPU 0 with stream priority 0 and optimization profile default[0];\n",
      "I0922 15:04:13.479383 74 model_repository_manager.cc:1240] successfully loaded 'riva-trt-riva_text_classification_default-nn-bert-base-uncased' version 1\n",
      "I0922 15:04:13.479640 74 model_repository_manager.cc:1066] loading: riva_text_classification_default:1\n",
      "I0922 15:04:13.580044 74 model_repository_manager.cc:1240] successfully loaded 'riva_text_classification_default' version 1\n",
      "I0922 15:04:13.580134 74 server.cc:504] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0922 15:04:13.580182 74 server.cc:543] \n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "| Backend     | Path                                                            | Config |\n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "| tensorrt    | <built-in>                                                      | {}     |\n",
      "| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {}     |\n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "\n",
      "I0922 15:04:13.580237 74 server.cc:586] \n",
      "+----------------------------------------------------------------+---------+--------+\n",
      "| Model                                                          | Version | Status |\n",
      "+----------------------------------------------------------------+---------+--------+\n",
      "| riva-trt-riva_text_classification_default-nn-bert-base-uncased | 1       | READY  |\n",
      "| riva_text_classification_default                               | 1       | READY  |\n",
      "| riva_tokenizer                                                 | 1       | READY  |\n",
      "+----------------------------------------------------------------+---------+--------+\n",
      "\n",
      "I0922 15:04:13.580356 74 tritonserver.cc:1658] \n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                  |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                 |\n",
      "| server_version                   | 2.9.0                                                                                                                                                                                  |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics |\n",
      "| model_repository_path[0]         | /data/models                                                                                                                                                                           |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                              |\n",
      "| strict_model_config              | 1                                                                                                                                                                                      |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                              |\n",
      "| cuda_memory_pool_byte_size{0}    | 1000000000                                                                                                                                                                             |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                    |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                      |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                     |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0922 15:04:13.581589 74 grpc_server.cc:4028] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "I0922 15:04:13.584424 74 http_server.cc:2761] Started HTTPService at 0.0.0.0:8000\n",
      "I0922 15:04:13.625858 74 http_server.cc:2780] Started Metrics Service at 0.0.0.0:8002\n",
      "  > Triton server is ready...\n",
      "I0922 15:04:14.636860   177 grpc_health.cc:27] RivaHealthService initialized with server: localhost:8001\n",
      "I0922 15:04:14.638870   177 grpc_riva_asr.cc:148] Setting uri for ASRServiceImpl\n",
      "I0922 15:04:14.638881   177 grpc_riva_asr.cc:149] Initializing different models\n",
      "I0922 15:04:14.647373   177 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 15:04:14.651857   177 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 15:04:14.652101   177 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 15:04:14.652113   177 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 15:04:14.656970   177 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 15:04:14.657716   177 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 15:04:14.658432   177 model_registry.cc:109] Successfully registered: 0 models.\n",
      "I0922 15:04:14.658449   177 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 15:04:14.658670   177 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 15:04:14.659891   177 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 15:04:14.664851   177 grpc_riva_asr.cc:173] Punctuation model does not exist on server\n",
      "I0922 15:04:14.664865   177 grpc_riva_asr.cc:177] Seeding RNG used for correlation id with time: 1663859054\n",
      "I0922 15:04:14.711541   177 grpc_riva_asr.cc:148] Setting uri for ASRServiceImpl\n",
      "I0922 15:04:14.711561   177 grpc_riva_asr.cc:149] Initializing different models\n",
      "I0922 15:04:14.711571   177 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 15:04:14.712018   177 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 15:04:14.712208   177 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 15:04:14.712217   177 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 15:04:14.712993   177 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 15:04:14.713742   177 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 15:04:14.714426   177 model_registry.cc:109] Successfully registered: 0 models.\n",
      "I0922 15:04:14.714440   177 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 15:04:14.714655   177 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 15:04:14.715804   177 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 15:04:14.716542   177 grpc_riva_asr.cc:173] Punctuation model does not exist on server\n",
      "I0922 15:04:14.716557   177 grpc_riva_asr.cc:177] Seeding RNG used for correlation id with time: 1663859054\n",
      "I0922 15:04:14.748684   177 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 15:04:14.749127   177 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 15:04:14.750768   177 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 15:04:14.751765   177 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 15:04:14.752110   177 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 15:04:14.752315   177 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 15:04:14.752327   177 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 15:04:14.752988   177 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 15:04:14.753648   177 model_registry.cc:104] 'Successfully registering riva_text_classification_default'\n",
      "I0922 15:04:14.753680   177 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 15:04:14.754344   177 model_registry.cc:109] Successfully registered: 1 models.\n",
      "I0922 15:04:14.754360   177 grpc_riva_nlp.cc:33] NLPService GRPC service started\n",
      "I0922 15:04:14.754366   177 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 15:04:14.754557   177 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 15:04:14.755779   177 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 15:04:14.756459   177 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 15:04:14.756814   177 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 15:04:14.757011   177 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 15:04:14.757025   177 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 15:04:14.757830   177 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 15:04:14.758563   177 model_registry.cc:104] 'Successfully registering riva_text_classification_default'\n",
      "I0922 15:04:14.758651   177 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 15:04:14.759341   177 model_registry.cc:109] Successfully registered: 1 models.\n",
      "I0922 15:04:14.759356   177 grpc_riva_nlp.cc:33] NLPService GRPC service started\n",
      "I0922 15:04:14.759368   177 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 15:04:14.759557   177 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 15:04:14.760797   177 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 15:04:14.761651   177 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 15:04:14.761943   177 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 15:04:14.762117   177 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 15:04:14.762128   177 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 15:04:14.762738   177 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 15:04:14.763392   177 model_registry.cc:104] 'Successfully registering riva_text_classification_default'\n",
      "I0922 15:04:14.763419   177 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 15:04:14.764274   177 model_registry.cc:109] Successfully registered: 1 models.\n",
      "I0922 15:04:14.764293   177 grpc_riva_nlp.cc:33] NLPService GRPC service started\n",
      "I0922 15:04:14.764586   177 riva_server.cc:91] NLP Service connected to Triton at localhost:8001\n",
      "I0922 15:04:14.764596   177 riva_server.cc:93] ASR Service connected to Triton at localhost:8001\n",
      "I0922 15:04:14.764600   177 riva_server.cc:96] Riva Conversational AI Server listening on 0.0.0.0:50051\n"
     ]
    }
   ],
   "source": [
    "# Check Riva running services \n",
    "!docker logs riva-speech \\\n",
    "    2>&1|tee my_assessment/step6.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riva Service Request (not graded)\n",
    "Although the SST-2 data set is trained on movie sentiments, it will likely work in our restaurant domain too.  Give it a try with the following queries or make up your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client app to test text classification on Riva\n",
      "Using model: riva_text_classification_default\n",
      "[('positive', 0.9695039987564087)]\n",
      "Client app to test text classification on Riva\n",
      "Using model: riva_text_classification_default\n",
      "[('negative', 0.6803079843521118)]\n",
      "Client app to test text classification on Riva\n",
      "Using model: riva_text_classification_default\n",
      "[('positive', 0.9965580105781555)]\n"
     ]
    }
   ],
   "source": [
    "%run my_assessment/sentiment_analysis_client.py --query \"I like pizza\"\n",
    "%run my_assessment/sentiment_analysis_client.py --query \"I don't like this restaurant\"\n",
    "%run my_assessment/sentiment_analysis_client.py --query \"yeah, sounds good\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Riva Services "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down Riva \n",
    "!bash $RIVA_QS/riva_stop.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 7: Submit You Assessment\n",
    "How were your results? \n",
    "\n",
    "If you are satisfied that you have completed the code correctly, and that your training and deployment are correct, you can submit your project as follows to the autograder:\n",
    "\n",
    "1. Go back to the GPU launch page and click the checkmark to run the assessment:\n",
    "\n",
    "<img src=\"images/assess/assessment_checkmark.png\">\n",
    "\n",
    "2. That's it!  You'll receive your grade feedback in the pop-up window. \n",
    "\n",
    "<img src=\"images/assess/assessment_pass_popup.png\">\n",
    "\n",
    "You can check your assessment progress in the course progress tab.  Note that partial values for the coding assessment **won't be visible here - it shows up as either 0 (if you achieve <65) or the full 70 points**.  Be sure to complete the additional questions to qualify for your final certificate!\n",
    "\n",
    "<img src=\"images/assess/progress.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
