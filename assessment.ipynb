{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment: Sentiment Analysis with TAO and Riva\n",
    "Sentiment analysis is a type of text classification, a common NLP task. \n",
    "Using a pretrained language model, such as BERT, it is possible to train a text classification model to classify sentences among defined categories.  In the case of sentiment analysis, there are only two categories: positive and negative.\n",
    "\n",
    "<img src=\"images/assess/sentiment_analysis.png\">\n",
    "\n",
    "### Table of Contents\n",
    "[The Problem](#The-Problem)<br>\n",
    "[Scoring](#Scoring)<br>\n",
    "[Step 1: Prepare the Project](#Step-1:-Prepare-the-Project)<br>\n",
    "[Step 2: Train](#Step-2:-Train)<br>\n",
    "[Step 3: Infer and Evaluate](#Step-3:-Infer-and-Evaluate)<br>\n",
    "[Step 4: Export Custom Model](#Step-4:-Export-Custom-Model)<br>\n",
    "[Step 5: Build and Deploy with Riva](#Step-5:-Build-and-Deploy-with-Riva)<br>\n",
    "[Step 6: Start Riva Services](#Step-6:-Start-Riva-Services)<br>\n",
    "[Step 7: Submit You Assessment](#Step-7:-Submit-You-Assessment)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Dependencies\n",
    "The steps in this notebook assume that you have:\n",
    "\n",
    "1. **NGC Credentials**<br>Be sure you have added your NGC credential as described in the [NGC Setup notebook](003_Intro_NGC_Setup.ipynb).  If you have restarted the course instance, you will need to repeat this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start fresh...\n",
    "# Clear Docker containers\n",
    "!docker kill $(docker ps -q)\n",
    "# Check for clean environment - this should be empty\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The Problem\n",
    "\n",
    "### SST-2 Movie Reviews\n",
    "The [Stanford Sentiment Treebank v2 (SST-2)](https://nlp.stanford.edu/sentiment/index.html) dataset is a corpus with fully labeled (two classes: positive and negative) single sentences extracted from movie reviews. Your task is to train a model using the dataset and deploy it to Riva, where you can run inference using the Riva API.\n",
    "\n",
    "### Your Project\n",
    "You are provided with labeled training and validation datasets, `train_small.tsv` and `dev_small.tsv` for the project.  There is also a test set, `test.tsv`, for a final test of the model.  All datasets are contained in the `tao/data/SST-2` directory.  You can open any of these files to take a look at the actual data and format:\n",
    "* [train_small.tsv](tao/data/SST-2/train_small.tsv)\n",
    "* [dev_small.tsv](tao/data/SST-2/dev_small.tsv)\n",
    "* [test.tsv](tao/data/SST-2/test.tsv)\n",
    "\n",
    "Your assignment is to train a [text classification model](https://docs.nvidia.com/tao/tao-toolkit/text/nlp/text_classification.html) with TAO using the `tao text_classification` launch command. After training, you must export the custom model, then deploy it using Riva.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scoring\n",
    "You will be assessed on your ability to effectively and efficiently train and deploy the model.  This coding assessment is worth 70 points, divided as follows:\n",
    "\n",
    "### Rubric\n",
    "\n",
    "| Step                    | Graded                                                 | FIXMEs?  | Points |\n",
    "|-------------------------|--------------------------------------------------------|----------|--------|\n",
    "| 1. Prepare the Project  | Specs and path definitions (spec files are present)    |  1       | 5      |\n",
    "| 2. Train                | Efficient training parameters (faster training)        |  5       | 15     |\n",
    "| 3. Infer and Evaluate   | Achieve good inference performance (F1 value >= 88)    |  0       | 10     |\n",
    "| 4. Export Custom Model  | Export for Riva (model exported in correct format)   |  1       | 12     |\n",
    "| 5. Build and Deploy     | Riva ServiceMaker (correct models built and loaded)  |  2       | 14     |\n",
    "| 6. Start Riva         | Riva Server (correct config; models run)             |  1       | 14     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you are very capable at this point of building the project without any help at all, some scaffolding is provided, including specific names for variables.  This is for the benefit of the autograder, so please use these constructs for your assessment.  In addition, a copy of the latest output for your executed cells in some cases is saved in the `my_assessment` directory.  Along the way, there are a few opportunities to check your work to see if you are on the right track. \n",
    "\n",
    "Once you are confident that you've built a reliable model, follow the instructions for submission at the end of the notebook.\n",
    "\n",
    "### Resources and Hints\n",
    "\n",
    "* **[TAO User's Guide](https://docs.nvidia.com/tao/tao-toolkit/index.html)**<br>\n",
    "* **[Riva Speech Skills User's Guide](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/index.html)**<br>\n",
    "* **TAO Example**<br>\n",
    "Review what you've learned in the [NER Fine-Tuning](007_NLP_Finetune_NER.ipynb) notebook to train, infer, evaluate, and export a TAO model.  The `tao token_classification` commands are very similar to the `tao text_classification` commands.\n",
    "* **Riva Deployment Example**<br>\n",
    "Review what you've learned in the [NER Model Deployment with Riva](008_NLP_Deploy_NER.ipynb) notebook to build and deploy the model, as well as start the Riva server.\n",
    "* **AMP Optimization Level (trainer.amp_level):**<br>\n",
    "To use mixed precision, set AMP to 'O1' or 'O2'; to train without mixed precision, set it to 'O0'.\n",
    "* **Precision (trainer.precision):**<br>\n",
    "To speed up training, you can set the precision to 16 instead of the standard 32 with little or no loss in accuracy.\n",
    "* **Number of epochs (trainer.max_epochs):**<br>\n",
    "The project is designed so that you should achieve success on this dataset with only 2 epochs, but feel free to run more. On a Tesla T4, this takes 5-6 minutes if you run it efficiently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1: Prepare the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Project Paths (not graded)\n",
    "This block is complete, but feel free to add to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the TAO paths for the project\n",
    "##### TAO paths - source\n",
    "SOURCE_MOUNT=\"/dli/task/tao\"\n",
    "DESTINATION_MOUNT = \"/workspace/mount\"\n",
    "\n",
    "##### TAO paths - source\n",
    "# Define location of the SST-2 dataset\n",
    "DATA = SOURCE_MOUNT+'/data/SST-2'\n",
    "# Directory where the .riva model is stored\n",
    "EXPORT_MODEL_LOC = SOURCE_MOUNT + '/results/sst2/export'\n",
    "\n",
    "##### TAO paths - destination (from the perspective of the TAO Docker)\n",
    "# The path to the specification YAML \n",
    "SPECS_DIR = DESTINATION_MOUNT + '/specs'\n",
    "# The results are saved at this path by default\n",
    "RESULTS_DIR = DESTINATION_MOUNT + '/results'\n",
    "# The data are saved at this path by default\n",
    "DATA_DIR = DESTINATION_MOUNT + '/data'\n",
    "# The results are saved at this path by default\n",
    "MODELS_DIR = DESTINATION_MOUNT + '/models'\n",
    "\n",
    "# Set your encryption key, and use the same key for all commands. Please use \"tlt_encode\" if you'd like to deploy the models later with NVIDIA Riva.\n",
    "KEY = 'tlt_encode'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Spec Files (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import rmtree\n",
    "\n",
    "# Delete the specs directory if it already exists\n",
    "folder = SOURCE_MOUNT + '/specs'\n",
    "if os.path.exists(folder):\n",
    "    rmtree(folder)\n",
    "\n",
    "# Get the text classification task spec files\n",
    "!tao #FIXME \\\n",
    "    -o $SPECS_DIR/text_classification \\\n",
    "    -r $RESULTS_DIR \\\n",
    "    2>&1|tee my_assessment/step1.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Train\n",
    "### Run the Trainer (graded)\n",
    "Review the `train.yaml` file you've just downloaded. Run the trainer in TAO and override YAML config values as necessary.\n",
    "\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell. Feel free to add/remove override values as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# For BERT training on SST-2:\n",
    "!tao #FIXME \\\n",
    "    -e $SPECS_DIR/text_classification/train.yaml \\\n",
    "    -g 1  \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2 \\\n",
    "    training_ds.file_path=#FIXME \\\n",
    "    validation_ds.file_path=#FIXME \\\n",
    "    model.class_labels.class_labels_file=$DATA_DIR/SST-2/label_ids.csv \\\n",
    "    trainer.amp_level=#FIXME \\\n",
    "    trainer.precision=#FIXME \\\n",
    "    trainer.max_epochs=2 \\\n",
    "    2>&1|tee my_assessment/step2.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train command produces a model file called `trained-model.tlt` saved at `results/sst2/checkpoints/trained-model.tlt`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 3: Infer and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Queries (not graded)\n",
    "Execute the following cell to create queries for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $SOURCE_MOUNT/specs/text_classification/infer.yaml\n",
    "\n",
    "# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.\n",
    "# TAO Spec file for inference using a previously pretrained BERT model for a text classification task.\n",
    "\n",
    "# \"Simulate\" user input: batch with four samples.\n",
    "input_batch:\n",
    "- \"this is a good script , good dialogue , funny even for adults .\"\n",
    "- \"the affectionate loopiness that once seemed congenital to demme s perspective has a tough time emerging from between the badly dated cutesy-pie mystery scenario a nd the newfangled hollywood post-production effects .\"\n",
    "- \" this piece of channel 5 grade trash is , quite frankly , an insult to the intelligence of the true genre enthusiast . \"\n",
    "- \"a delightful coming-of-age story .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on the Trained Model (not graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run inference on user data:\n",
    "!tao text_classification infer \\\n",
    "    -e $SPECS_DIR/text_classification/infer.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your Model (results graded)\n",
    "Execute the following cell without changes.  Review your output to see if you had an F1 result above the 88% goal.  If not, you may need to retrain your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For BERT evaluation on SST-2:\n",
    "!tao text_classification evaluate \\\n",
    "    -e $SPECS_DIR/text_classification/evaluate.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/eval \\\n",
    "    test_ds.file_path=$DATA_DIR/SST-2/test.tsv \\\n",
    "    test_ds.batch_size=32 \\\n",
    "    test_ds.num_samples=-1 \\\n",
    "    2>&1|tee my_assessment/step3.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4: Export Custom Model\n",
    "### Export the Model for Riva (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  For export to Riva:\n",
    "!tao text_classification export \\\n",
    "    -e $SPECS_DIR/text_classification/export.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/export/ \\\n",
    "    export_format=#FIXME \\\n",
    "    export_to=tc-model.riva \\\n",
    "    2>&1|tee my_assessment/step4.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work - does the exported tc-model.riva model exist?\n",
    "!ls $EXPORT_MODEL_LOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 5: Build and Deploy with Riva\n",
    "### Set up Project Paths (not graded)\n",
    "This block is complete, but feel free to add to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Riva paths for the project\n",
    "WORKSPACE = \"/dli/task\"\n",
    "\n",
    "##### Riva Paths\n",
    "# ServiceMaker Docker\n",
    "RIVA_SM_CONTAINER = \"nvcr.io/nvidia/riva/riva-speech:1.4.0-beta-servicemaker\"\n",
    "\n",
    "# Model output directories\n",
    "RMIR_LOC = WORKSPACE + \"/riva/riva_quickstart/models_repo_assessment/rmir\"\n",
    "RIVA_MODEL_LOC = WORKSPACE + '/riva/riva_quickstart/models_repo_assessment'\n",
    "\n",
    "# Model Names\n",
    "EXPORT_MODEL_NAME = \"tc-model.riva\"  \n",
    "RMIR_MODEL_NAME = \"tc-model.rmir\"\n",
    "\n",
    "# Riva Quick Start \n",
    "RIVA_QS = WORKSPACE + \"/riva/riva_quickstart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Deploy with Riva ServiceMaker (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Syntax: riva-build <task-name> output-dir-for-rmir/model.rmir:key dir-for-riva/model.riva:key\n",
    "!docker run --rm --gpus 1 \\\n",
    "    -v $EXPORT_MODEL_LOC:/tao \\\n",
    "    -v $RMIR_LOC:/riva \\\n",
    "    $RIVA_SM_CONTAINER -- \\\n",
    "    riva-build #FIXME \\\n",
    "    -f /riva/$RMIR_MODEL_NAME:$KEY /tao/$EXPORT_MODEL_NAME:$KEY \\\n",
    "    2>&1|tee my_assessment/step5.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work - does the exported tc-model.rmir model exist?\n",
    "!ls $RMIR_LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Syntax: riva-deploy -f dir-for-rmir/model.rmir:key output-dir-for-repository\n",
    "!docker run --rm --gpus 1 \\\n",
    "    -v $RIVA_MODEL_LOC:/data \\\n",
    "    $RIVA_SM_CONTAINER -- \\\n",
    "    riva-deploy -f #FIXME \\\n",
    "    /data/models/ \\\n",
    "    2>&1|tee -a my_assessment/step5.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work - are there optimized models for text classification?\n",
    "!ls $RIVA_MODEL_LOC/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 6: Start Riva Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Start Riva (graded)\n",
    "Next, modify the [config.sh](riva/riva_quickstart/config.sh) to enable relevant Riva services. \n",
    "In this case, we want to start NLP services, provide the encryption key, and update the path to the model repository (`RIVA_MODEL_LOC`). \n",
    "Open the [config.sh](riva/riva_quickstart/config.sh) and make changes where necessary, then start the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Riva Start. This will deploy the model.\n",
    "!cd $RIVA_QS && bash riva_start.sh config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check Riva running services \n",
    "!docker logs riva-speech \\\n",
    "    2>&1|tee my_assessment/step6.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riva Service Request (not graded)\n",
    "Although the SST-2 data set is trained on movie sentiments, it will likely work in our restaurant domain too.  Give it a try with the following queries or make up your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run my_assessment/sentiment_analysis_client.py --query \"I like pizza\"\n",
    "%run my_assessment/sentiment_analysis_client.py --query \"I don't like this restaurant\"\n",
    "%run my_assessment/sentiment_analysis_client.py --query \"yeah, sounds good\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Riva Services "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down Riva \n",
    "!bash $RIVA_QS/riva_stop.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 7: Submit You Assessment\n",
    "How were your results? \n",
    "\n",
    "If you are satisfied that you have completed the code correctly, and that your training and deployment are correct, you can submit your project as follows to the autograder:\n",
    "\n",
    "1. Go back to the GPU launch page and click the checkmark to run the assessment:\n",
    "\n",
    "<img src=\"images/assess/assessment_checkmark.png\">\n",
    "\n",
    "2. That's it!  You'll receive your grade feedback in the pop-up window. \n",
    "\n",
    "<img src=\"images/assess/assessment_pass_popup.png\">\n",
    "\n",
    "You can check your assessment progress in the course progress tab.  Note that partial values for the coding assessment **won't be visible here - it shows up as either 0 (if you achieve <65) or the full 70 points**.  Be sure to complete the additional questions to qualify for your final certificate!\n",
    "\n",
    "<img src=\"images/assess/progress.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
