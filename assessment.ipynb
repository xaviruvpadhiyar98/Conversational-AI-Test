{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment: Sentiment Analysis with TAO and Riva\n",
    "Sentiment analysis is a type of text classification, a common NLP task. \n",
    "Using a pretrained language model, such as BERT, it is possible to train a text classification model to classify sentences among defined categories.  In the case of sentiment analysis, there are only two categories: positive and negative.\n",
    "\n",
    "<img src=\"images/assess/sentiment_analysis.png\">\n",
    "\n",
    "### Table of Contents\n",
    "[The Problem](#The-Problem)<br>\n",
    "[Scoring](#Scoring)<br>\n",
    "[Step 1: Prepare the Project](#Step-1:-Prepare-the-Project)<br>\n",
    "[Step 2: Train](#Step-2:-Train)<br>\n",
    "[Step 3: Infer and Evaluate](#Step-3:-Infer-and-Evaluate)<br>\n",
    "[Step 4: Export Custom Model](#Step-4:-Export-Custom-Model)<br>\n",
    "[Step 5: Build and Deploy with Riva](#Step-5:-Build-and-Deploy-with-Riva)<br>\n",
    "[Step 6: Start Riva Services](#Step-6:-Start-Riva-Services)<br>\n",
    "[Step 7: Submit You Assessment](#Step-7:-Submit-You-Assessment)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Dependencies\n",
    "The steps in this notebook assume that you have:\n",
    "\n",
    "1. **NGC Credentials**<br>Be sure you have added your NGC credential as described in the [NGC Setup notebook](003_Intro_NGC_Setup.ipynb).  If you have restarted the course instance, you will need to repeat this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"docker kill\" requires at least 1 argument.\n",
      "See 'docker kill --help'.\n",
      "\n",
      "Usage:  docker kill [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Kill one or more running containers\n",
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "# Start fresh...\n",
    "# Clear Docker containers\n",
    "!docker kill $(docker ps -q)\n",
    "# Check for clean environment - this should be empty\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# The Problem\n",
    "\n",
    "### SST-2 Movie Reviews\n",
    "The [Stanford Sentiment Treebank v2 (SST-2)](https://nlp.stanford.edu/sentiment/index.html) dataset is a corpus with fully labeled (two classes: positive and negative) single sentences extracted from movie reviews. Your task is to train a model using the dataset and deploy it to Riva, where you can run inference using the Riva API.\n",
    "\n",
    "### Your Project\n",
    "You are provided with labeled training and validation datasets, `train_small.tsv` and `dev_small.tsv` for the project.  There is also a test set, `test.tsv`, for a final test of the model.  All datasets are contained in the `tao/data/SST-2` directory.  You can open any of these files to take a look at the actual data and format:\n",
    "* [train_small.tsv](tao/data/SST-2/train_small.tsv)\n",
    "* [dev_small.tsv](tao/data/SST-2/dev_small.tsv)\n",
    "* [test.tsv](tao/data/SST-2/test.tsv)\n",
    "\n",
    "Your assignment is to train a [text classification model](https://docs.nvidia.com/tao/tao-toolkit/text/nlp/text_classification.html) with TAO using the `tao text_classification` launch command. After training, you must export the custom model, then deploy it using Riva.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scoring\n",
    "You will be assessed on your ability to effectively and efficiently train and deploy the model.  This coding assessment is worth 70 points, divided as follows:\n",
    "\n",
    "### Rubric\n",
    "\n",
    "| Step                    | Graded                                                 | FIXMEs?  | Points |\n",
    "|-------------------------|--------------------------------------------------------|----------|--------|\n",
    "| 1. Prepare the Project  | Specs and path definitions (spec files are present)    |  1       | 5      |\n",
    "| 2. Train                | Efficient training parameters (faster training)        |  5       | 15     |\n",
    "| 3. Infer and Evaluate   | Achieve good inference performance (F1 value >= 88)    |  0       | 10     |\n",
    "| 4. Export Custom Model  | Export for Riva (model exported in correct format)   |  1       | 12     |\n",
    "| 5. Build and Deploy     | Riva ServiceMaker (correct models built and loaded)  |  2       | 14     |\n",
    "| 6. Start Riva         | Riva Server (correct config; models run)             |  1       | 14     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you are very capable at this point of building the project without any help at all, some scaffolding is provided, including specific names for variables.  This is for the benefit of the autograder, so please use these constructs for your assessment.  In addition, a copy of the latest output for your executed cells in some cases is saved in the `my_assessment` directory.  Along the way, there are a few opportunities to check your work to see if you are on the right track. \n",
    "\n",
    "Once you are confident that you've built a reliable model, follow the instructions for submission at the end of the notebook.\n",
    "\n",
    "### Resources and Hints\n",
    "\n",
    "* **[TAO User's Guide](https://docs.nvidia.com/tao/tao-toolkit/index.html)**<br>\n",
    "* **[Riva Speech Skills User's Guide](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/index.html)**<br>\n",
    "* **TAO Example**<br>\n",
    "Review what you've learned in the [NER Fine-Tuning](007_NLP_Finetune_NER.ipynb) notebook to train, infer, evaluate, and export a TAO model.  The `tao token_classification` commands are very similar to the `tao text_classification` commands.\n",
    "* **Riva Deployment Example**<br>\n",
    "Review what you've learned in the [NER Model Deployment with Riva](008_NLP_Deploy_NER.ipynb) notebook to build and deploy the model, as well as start the Riva server.\n",
    "* **AMP Optimization Level (trainer.amp_level):**<br>\n",
    "To use mixed precision, set AMP to 'O1' or 'O2'; to train without mixed precision, set it to 'O0'.\n",
    "* **Precision (trainer.precision):**<br>\n",
    "To speed up training, you can set the precision to 16 instead of the standard 32 with little or no loss in accuracy.\n",
    "* **Number of epochs (trainer.max_epochs):**<br>\n",
    "The project is designed so that you should achieve success on this dataset with only 2 epochs, but feel free to run more. On a Tesla T4, this takes 5-6 minutes if you run it efficiently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1: Prepare the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Project Paths (not graded)\n",
    "This block is complete, but feel free to add to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the TAO paths for the project\n",
    "##### TAO paths - source\n",
    "SOURCE_MOUNT=\"/dli/task/tao\"\n",
    "DESTINATION_MOUNT = \"/workspace/mount\"\n",
    "\n",
    "##### TAO paths - source\n",
    "# Define location of the SST-2 dataset\n",
    "DATA = SOURCE_MOUNT+'/data/SST-2'\n",
    "# Directory where the .riva model is stored\n",
    "EXPORT_MODEL_LOC = SOURCE_MOUNT + '/results/sst2/export'\n",
    "\n",
    "##### TAO paths - destination (from the perspective of the TAO Docker)\n",
    "# The path to the specification YAML \n",
    "SPECS_DIR = DESTINATION_MOUNT + '/specs'\n",
    "# The results are saved at this path by default\n",
    "RESULTS_DIR = DESTINATION_MOUNT + '/results'\n",
    "# The data are saved at this path by default\n",
    "DATA_DIR = DESTINATION_MOUNT + '/data'\n",
    "# The results are saved at this path by default\n",
    "MODELS_DIR = DESTINATION_MOUNT + '/models'\n",
    "\n",
    "# Set your encryption key, and use the same key for all commands. Please use \"tlt_encode\" if you'd like to deploy the models later with NVIDIA Riva.\n",
    "KEY = 'tlt_encode'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Spec Files (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 13:02:44,669 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 13:02:44,785 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 13:02:47 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo I 2022-09-22 13:02:49 tlt_logging:20] Experiment configuration:\n",
      "    exp_manager:\n",
      "      task_name: download_specs\n",
      "      explicit_log_dir: /workspace/mount/results\n",
      "    source_data_dir: /opt/conda/lib/python3.8/site-packages/nlp/text_classification/experiment_specs\n",
      "    target_data_dir: /workspace/mount/specs/text_classification\n",
      "    workflow: nlp\n",
      "    \n",
      "[NeMo W 2022-09-22 13:02:49 exp_manager:26] Exp_manager is logging to `/workspace/mount/results``, but it already exists.\n",
      "[NeMo I 2022-09-22 13:02:49 download_specs:73] Default specification files for nlp downloaded to '/workspace/mount/specs/text_classification'\n",
      "[NeMo I 2022-09-22 13:02:49 download_specs:74] Experiment logs saved to '/workspace/mount/results'\n",
      "2022-09-22 13:02:50,139 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import rmtree\n",
    "\n",
    "# Delete the specs directory if it already exists\n",
    "folder = SOURCE_MOUNT + '/specs'\n",
    "if os.path.exists(folder):\n",
    "    rmtree(folder)\n",
    "\n",
    "# Get the text classification task spec files\n",
    "!tao text_classification download_specs \\\n",
    "    -o $SPECS_DIR/text_classification \\\n",
    "    -r $RESULTS_DIR \\\n",
    "    2>&1|tee my_assessment/step1.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Train\n",
    "### Run the Trainer (graded)\n",
    "Review the `train.yaml` file you've just downloaded. Run the trainer in TAO and override YAML config values as necessary.\n",
    "\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell. Feel free to add/remove override values as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 13:02:50,580 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 13:02:50,681 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 13:02:53 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-09-22 13:02:56 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-09-22 13:02:57 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: ???\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/sst2\n",
      "      exp_dir: null\n",
      "      name: trained-model\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: true\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .tlt\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    model:\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      language_model:\n",
      "        pretrained_model_name: bert-base-uncased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      classifier_head:\n",
      "        num_output_layers: 2\n",
      "        fc_dropout: 0.1\n",
      "      class_labels:\n",
      "        class_labels_file: /workspace/mount/data/SST-2/label_ids.csv\n",
      "      dataset:\n",
      "        num_classes: 2\n",
      "        do_lower_case: false\n",
      "        max_seq_length: 256\n",
      "        class_balancing: null\n",
      "        use_cache: false\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 3\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 16\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: '01'\n",
      "    training_ds:\n",
      "      file_path: /workspace/mount/data/SST-2/train.tsv\n",
      "      batch_size: 64\n",
      "      shuffle: true\n",
      "      num_samples: -1\n",
      "      num_workers: 3\n",
      "      drop_last: false\n",
      "      pin_memory: false\n",
      "    validation_ds:\n",
      "      file_path: /workspace/mount/data/SST-2/test.tsv\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "      num_workers: 3\n",
      "      drop_last: false\n",
      "      pin_memory: false\n",
      "    optim:\n",
      "      name: adam\n",
      "      lr: 2.0e-05\n",
      "      betas:\n",
      "      - 0.9\n",
      "      - 0.999\n",
      "      weight_decay: 0.01\n",
      "      sched:\n",
      "        name: WarmupAnnealing\n",
      "        warmup_steps: null\n",
      "        warmup_ratio: 0.1\n",
      "        last_epoch: -1\n",
      "        monitor: val_loss\n",
      "        reduce_on_plateau: false\n",
      "    encryption_key: '******'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "Using native 16bit precision.\n",
      "[NeMo W 2022-09-22 13:02:57 exp_manager:380] Exp_manager is logging to /workspace/mount/results/sst2, but it already exists.\n",
      "[NeMo I 2022-09-22 13:02:57 exp_manager:328] Resuming from /workspace/mount/results/sst2/checkpoints/trained-model-last.ckpt\n",
      "[NeMo I 2022-09-22 13:02:57 exp_manager:194] Experiments will be logged at /workspace/mount/results/sst2\n",
      "[NeMo W 2022-09-22 13:02:57 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory /workspace/mount/results/sst2/checkpoints exists and is not empty.\n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n",
      "Lock 140208913232320 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100% 570/570 [00:00<00:00, 1.05MB/s]\n",
      "Lock 140208913232320 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140208912711392 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 1.44MB/s]\n",
      "Lock 140208912711392 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140208913232320 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100% 28.0/28.0 [00:00<00:00, 57.8kB/s]\n",
      "Lock 140208913232320 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140208913232320 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100% 466k/466k [00:00<00:00, 2.67MB/s]\n",
      "Lock 140208913232320 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "Lock 140208912268496 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100% 440M/440M [00:04<00:00, 97.3MB/s] \n",
      "Lock 140208912268496 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:120] Read 67349 examples from /workspace/mount/data/SST-2/train.tsv.\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:239] example 0: ['under', 'the', 'strain', 'of', 'its', 'plot', 'contrivances', 'and', 'its', 'need', 'to', 'reassure']\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:240] subtokens: [CLS] under the strain of its plot con ##tri ##vances and its need to reassure [SEP]\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:241] input_ids: 101 2104 1996 10178 1997 2049 5436 9530 18886 26711 1998 2049 2342 2000 24647 102\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:239] example 1: ['as', 'dreadful']\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:240] subtokens: [CLS] as dreadful [SEP]\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:241] input_ids: 101 2004 21794 102\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:242] segment_ids: 0 0 0 0\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:243] input_mask: 1 1 1 1\n",
      "[NeMo I 2022-09-22 13:03:07 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2022-09-22 13:03:47 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-09-22 13:03:47 data_preprocessing:297] Min: 3 |                  Max: 66 |                  Mean: 13.319262349849293 |                  Median: 10.0\n",
      "[NeMo I 2022-09-22 13:03:47 data_preprocessing:303] 75 percentile: 18.00\n",
      "[NeMo I 2022-09-22 13:03:47 data_preprocessing:304] 99 percentile: 44.00\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:120] Read 100 examples from /workspace/mount/data/SST-2/test.tsv.\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:239] example 0: ['not', 'the', 'kind', 'of', 'film', 'that', 'will', 'appeal', 'to', 'a', 'mainstream', 'american', 'audience', ',', 'but', 'there', 'is', 'a', 'certain', 'charm', 'about', 'the', 'film', 'that', 'makes', 'it', 'a', 'suitable', 'entry', 'into', 'the', 'fest', 'circuit', '.']\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:240] subtokens: [CLS] not the kind of film that will appeal to a mainstream american audience , but there is a certain charm about the film that makes it a suitable entry into the fest circuit . [SEP]\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:241] input_ids: 101 2025 1996 2785 1997 2143 2008 2097 5574 2000 1037 7731 2137 4378 1010 2021 2045 2003 1037 3056 11084 2055 1996 2143 2008 3084 2009 1037 7218 4443 2046 1996 17037 4984 1012 102\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:239] example 1: ['it', \"'s\", 'a', 'beautiful', 'madness', '.']\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:240] subtokens: [CLS] it ' s a beautiful madness . [SEP]\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:241] input_ids: 101 2009 1005 1055 1037 3376 12013 1012 102\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 13:03:49 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 13:03:49 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-09-22 13:03:49 data_preprocessing:297] Min: 7 |                  Max: 54 |                  Mean: 25.85 |                  Median: 25.0\n",
      "[NeMo I 2022-09-22 13:03:49 data_preprocessing:303] 75 percentile: 34.00\n",
      "[NeMo I 2022-09-22 13:03:49 data_preprocessing:304] 99 percentile: 52.02\n",
      "[NeMo I 2022-09-22 13:03:49 modelPT:753] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        eps: 1e-08\n",
      "        lr: 2e-05\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2022-09-22 13:03:49 lr_scheduler:617] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7f84d524c0a0>\" \n",
      "    will be used during training (effective maximum steps = 3159) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    max_steps: 3159\n",
      "    )\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "[NeMo I 2022-09-22 13:03:50 modelPT:627] No optimizer config provided, therefore no optimizer was created\n",
      "\n",
      "    | Name                                                   | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                             | BertEncoder          | 109 M \n",
      "1   | bert_model.embeddings                                  | BertEmbeddings       | 23.8 M\n",
      "2   | bert_model.embeddings.word_embeddings                  | Embedding            | 23.4 M\n",
      "3   | bert_model.embeddings.position_embeddings              | Embedding            | 393 K \n",
      "4   | bert_model.embeddings.token_type_embeddings            | Embedding            | 1.5 K \n",
      "5   | bert_model.embeddings.LayerNorm                        | LayerNorm            | 1.5 K \n",
      "6   | bert_model.embeddings.dropout                          | Dropout              | 0     \n",
      "7   | bert_model.encoder                                     | BertEncoder          | 85.1 M\n",
      "8   | bert_model.encoder.layer                               | ModuleList           | 85.1 M\n",
      "9   | bert_model.encoder.layer.0                             | BertLayer            | 7.1 M \n",
      "10  | bert_model.encoder.layer.0.attention                   | BertAttention        | 2.4 M \n",
      "11  | bert_model.encoder.layer.0.attention.self              | BertSelfAttention    | 1.8 M \n",
      "12  | bert_model.encoder.layer.0.attention.self.query        | Linear               | 590 K \n",
      "13  | bert_model.encoder.layer.0.attention.self.key          | Linear               | 590 K \n",
      "14  | bert_model.encoder.layer.0.attention.self.value        | Linear               | 590 K \n",
      "15  | bert_model.encoder.layer.0.attention.self.dropout      | Dropout              | 0     \n",
      "16  | bert_model.encoder.layer.0.attention.output            | BertSelfOutput       | 592 K \n",
      "17  | bert_model.encoder.layer.0.attention.output.dense      | Linear               | 590 K \n",
      "18  | bert_model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "19  | bert_model.encoder.layer.0.attention.output.dropout    | Dropout              | 0     \n",
      "20  | bert_model.encoder.layer.0.intermediate                | BertIntermediate     | 2.4 M \n",
      "21  | bert_model.encoder.layer.0.intermediate.dense          | Linear               | 2.4 M \n",
      "22  | bert_model.encoder.layer.0.output                      | BertOutput           | 2.4 M \n",
      "23  | bert_model.encoder.layer.0.output.dense                | Linear               | 2.4 M \n",
      "24  | bert_model.encoder.layer.0.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "25  | bert_model.encoder.layer.0.output.dropout              | Dropout              | 0     \n",
      "26  | bert_model.encoder.layer.1                             | BertLayer            | 7.1 M \n",
      "27  | bert_model.encoder.layer.1.attention                   | BertAttention        | 2.4 M \n",
      "28  | bert_model.encoder.layer.1.attention.self              | BertSelfAttention    | 1.8 M \n",
      "29  | bert_model.encoder.layer.1.attention.self.query        | Linear               | 590 K \n",
      "30  | bert_model.encoder.layer.1.attention.self.key          | Linear               | 590 K \n",
      "31  | bert_model.encoder.layer.1.attention.self.value        | Linear               | 590 K \n",
      "32  | bert_model.encoder.layer.1.attention.self.dropout      | Dropout              | 0     \n",
      "33  | bert_model.encoder.layer.1.attention.output            | BertSelfOutput       | 592 K \n",
      "34  | bert_model.encoder.layer.1.attention.output.dense      | Linear               | 590 K \n",
      "35  | bert_model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "36  | bert_model.encoder.layer.1.attention.output.dropout    | Dropout              | 0     \n",
      "37  | bert_model.encoder.layer.1.intermediate                | BertIntermediate     | 2.4 M \n",
      "38  | bert_model.encoder.layer.1.intermediate.dense          | Linear               | 2.4 M \n",
      "39  | bert_model.encoder.layer.1.output                      | BertOutput           | 2.4 M \n",
      "40  | bert_model.encoder.layer.1.output.dense                | Linear               | 2.4 M \n",
      "41  | bert_model.encoder.layer.1.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "42  | bert_model.encoder.layer.1.output.dropout              | Dropout              | 0     \n",
      "43  | bert_model.encoder.layer.2                             | BertLayer            | 7.1 M \n",
      "44  | bert_model.encoder.layer.2.attention                   | BertAttention        | 2.4 M \n",
      "45  | bert_model.encoder.layer.2.attention.self              | BertSelfAttention    | 1.8 M \n",
      "46  | bert_model.encoder.layer.2.attention.self.query        | Linear               | 590 K \n",
      "47  | bert_model.encoder.layer.2.attention.self.key          | Linear               | 590 K \n",
      "48  | bert_model.encoder.layer.2.attention.self.value        | Linear               | 590 K \n",
      "49  | bert_model.encoder.layer.2.attention.self.dropout      | Dropout              | 0     \n",
      "50  | bert_model.encoder.layer.2.attention.output            | BertSelfOutput       | 592 K \n",
      "51  | bert_model.encoder.layer.2.attention.output.dense      | Linear               | 590 K \n",
      "52  | bert_model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "53  | bert_model.encoder.layer.2.attention.output.dropout    | Dropout              | 0     \n",
      "54  | bert_model.encoder.layer.2.intermediate                | BertIntermediate     | 2.4 M \n",
      "55  | bert_model.encoder.layer.2.intermediate.dense          | Linear               | 2.4 M \n",
      "56  | bert_model.encoder.layer.2.output                      | BertOutput           | 2.4 M \n",
      "57  | bert_model.encoder.layer.2.output.dense                | Linear               | 2.4 M \n",
      "58  | bert_model.encoder.layer.2.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "59  | bert_model.encoder.layer.2.output.dropout              | Dropout              | 0     \n",
      "60  | bert_model.encoder.layer.3                             | BertLayer            | 7.1 M \n",
      "61  | bert_model.encoder.layer.3.attention                   | BertAttention        | 2.4 M \n",
      "62  | bert_model.encoder.layer.3.attention.self              | BertSelfAttention    | 1.8 M \n",
      "63  | bert_model.encoder.layer.3.attention.self.query        | Linear               | 590 K \n",
      "64  | bert_model.encoder.layer.3.attention.self.key          | Linear               | 590 K \n",
      "65  | bert_model.encoder.layer.3.attention.self.value        | Linear               | 590 K \n",
      "66  | bert_model.encoder.layer.3.attention.self.dropout      | Dropout              | 0     \n",
      "67  | bert_model.encoder.layer.3.attention.output            | BertSelfOutput       | 592 K \n",
      "68  | bert_model.encoder.layer.3.attention.output.dense      | Linear               | 590 K \n",
      "69  | bert_model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "70  | bert_model.encoder.layer.3.attention.output.dropout    | Dropout              | 0     \n",
      "71  | bert_model.encoder.layer.3.intermediate                | BertIntermediate     | 2.4 M \n",
      "72  | bert_model.encoder.layer.3.intermediate.dense          | Linear               | 2.4 M \n",
      "73  | bert_model.encoder.layer.3.output                      | BertOutput           | 2.4 M \n",
      "74  | bert_model.encoder.layer.3.output.dense                | Linear               | 2.4 M \n",
      "75  | bert_model.encoder.layer.3.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "76  | bert_model.encoder.layer.3.output.dropout              | Dropout              | 0     \n",
      "77  | bert_model.encoder.layer.4                             | BertLayer            | 7.1 M \n",
      "78  | bert_model.encoder.layer.4.attention                   | BertAttention        | 2.4 M \n",
      "79  | bert_model.encoder.layer.4.attention.self              | BertSelfAttention    | 1.8 M \n",
      "80  | bert_model.encoder.layer.4.attention.self.query        | Linear               | 590 K \n",
      "81  | bert_model.encoder.layer.4.attention.self.key          | Linear               | 590 K \n",
      "82  | bert_model.encoder.layer.4.attention.self.value        | Linear               | 590 K \n",
      "83  | bert_model.encoder.layer.4.attention.self.dropout      | Dropout              | 0     \n",
      "84  | bert_model.encoder.layer.4.attention.output            | BertSelfOutput       | 592 K \n",
      "85  | bert_model.encoder.layer.4.attention.output.dense      | Linear               | 590 K \n",
      "86  | bert_model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "87  | bert_model.encoder.layer.4.attention.output.dropout    | Dropout              | 0     \n",
      "88  | bert_model.encoder.layer.4.intermediate                | BertIntermediate     | 2.4 M \n",
      "89  | bert_model.encoder.layer.4.intermediate.dense          | Linear               | 2.4 M \n",
      "90  | bert_model.encoder.layer.4.output                      | BertOutput           | 2.4 M \n",
      "91  | bert_model.encoder.layer.4.output.dense                | Linear               | 2.4 M \n",
      "92  | bert_model.encoder.layer.4.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "93  | bert_model.encoder.layer.4.output.dropout              | Dropout              | 0     \n",
      "94  | bert_model.encoder.layer.5                             | BertLayer            | 7.1 M \n",
      "95  | bert_model.encoder.layer.5.attention                   | BertAttention        | 2.4 M \n",
      "96  | bert_model.encoder.layer.5.attention.self              | BertSelfAttention    | 1.8 M \n",
      "97  | bert_model.encoder.layer.5.attention.self.query        | Linear               | 590 K \n",
      "98  | bert_model.encoder.layer.5.attention.self.key          | Linear               | 590 K \n",
      "99  | bert_model.encoder.layer.5.attention.self.value        | Linear               | 590 K \n",
      "100 | bert_model.encoder.layer.5.attention.self.dropout      | Dropout              | 0     \n",
      "101 | bert_model.encoder.layer.5.attention.output            | BertSelfOutput       | 592 K \n",
      "102 | bert_model.encoder.layer.5.attention.output.dense      | Linear               | 590 K \n",
      "103 | bert_model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "104 | bert_model.encoder.layer.5.attention.output.dropout    | Dropout              | 0     \n",
      "105 | bert_model.encoder.layer.5.intermediate                | BertIntermediate     | 2.4 M \n",
      "106 | bert_model.encoder.layer.5.intermediate.dense          | Linear               | 2.4 M \n",
      "107 | bert_model.encoder.layer.5.output                      | BertOutput           | 2.4 M \n",
      "108 | bert_model.encoder.layer.5.output.dense                | Linear               | 2.4 M \n",
      "109 | bert_model.encoder.layer.5.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "110 | bert_model.encoder.layer.5.output.dropout              | Dropout              | 0     \n",
      "111 | bert_model.encoder.layer.6                             | BertLayer            | 7.1 M \n",
      "112 | bert_model.encoder.layer.6.attention                   | BertAttention        | 2.4 M \n",
      "113 | bert_model.encoder.layer.6.attention.self              | BertSelfAttention    | 1.8 M \n",
      "114 | bert_model.encoder.layer.6.attention.self.query        | Linear               | 590 K \n",
      "115 | bert_model.encoder.layer.6.attention.self.key          | Linear               | 590 K \n",
      "116 | bert_model.encoder.layer.6.attention.self.value        | Linear               | 590 K \n",
      "117 | bert_model.encoder.layer.6.attention.self.dropout      | Dropout              | 0     \n",
      "118 | bert_model.encoder.layer.6.attention.output            | BertSelfOutput       | 592 K \n",
      "119 | bert_model.encoder.layer.6.attention.output.dense      | Linear               | 590 K \n",
      "120 | bert_model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "121 | bert_model.encoder.layer.6.attention.output.dropout    | Dropout              | 0     \n",
      "122 | bert_model.encoder.layer.6.intermediate                | BertIntermediate     | 2.4 M \n",
      "123 | bert_model.encoder.layer.6.intermediate.dense          | Linear               | 2.4 M \n",
      "124 | bert_model.encoder.layer.6.output                      | BertOutput           | 2.4 M \n",
      "125 | bert_model.encoder.layer.6.output.dense                | Linear               | 2.4 M \n",
      "126 | bert_model.encoder.layer.6.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "127 | bert_model.encoder.layer.6.output.dropout              | Dropout              | 0     \n",
      "128 | bert_model.encoder.layer.7                             | BertLayer            | 7.1 M \n",
      "129 | bert_model.encoder.layer.7.attention                   | BertAttention        | 2.4 M \n",
      "130 | bert_model.encoder.layer.7.attention.self              | BertSelfAttention    | 1.8 M \n",
      "131 | bert_model.encoder.layer.7.attention.self.query        | Linear               | 590 K \n",
      "132 | bert_model.encoder.layer.7.attention.self.key          | Linear               | 590 K \n",
      "133 | bert_model.encoder.layer.7.attention.self.value        | Linear               | 590 K \n",
      "134 | bert_model.encoder.layer.7.attention.self.dropout      | Dropout              | 0     \n",
      "135 | bert_model.encoder.layer.7.attention.output            | BertSelfOutput       | 592 K \n",
      "136 | bert_model.encoder.layer.7.attention.output.dense      | Linear               | 590 K \n",
      "137 | bert_model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "138 | bert_model.encoder.layer.7.attention.output.dropout    | Dropout              | 0     \n",
      "139 | bert_model.encoder.layer.7.intermediate                | BertIntermediate     | 2.4 M \n",
      "140 | bert_model.encoder.layer.7.intermediate.dense          | Linear               | 2.4 M \n",
      "141 | bert_model.encoder.layer.7.output                      | BertOutput           | 2.4 M \n",
      "142 | bert_model.encoder.layer.7.output.dense                | Linear               | 2.4 M \n",
      "143 | bert_model.encoder.layer.7.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "144 | bert_model.encoder.layer.7.output.dropout              | Dropout              | 0     \n",
      "145 | bert_model.encoder.layer.8                             | BertLayer            | 7.1 M \n",
      "146 | bert_model.encoder.layer.8.attention                   | BertAttention        | 2.4 M \n",
      "147 | bert_model.encoder.layer.8.attention.self              | BertSelfAttention    | 1.8 M \n",
      "148 | bert_model.encoder.layer.8.attention.self.query        | Linear               | 590 K \n",
      "149 | bert_model.encoder.layer.8.attention.self.key          | Linear               | 590 K \n",
      "150 | bert_model.encoder.layer.8.attention.self.value        | Linear               | 590 K \n",
      "151 | bert_model.encoder.layer.8.attention.self.dropout      | Dropout              | 0     \n",
      "152 | bert_model.encoder.layer.8.attention.output            | BertSelfOutput       | 592 K \n",
      "153 | bert_model.encoder.layer.8.attention.output.dense      | Linear               | 590 K \n",
      "154 | bert_model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "155 | bert_model.encoder.layer.8.attention.output.dropout    | Dropout              | 0     \n",
      "156 | bert_model.encoder.layer.8.intermediate                | BertIntermediate     | 2.4 M \n",
      "157 | bert_model.encoder.layer.8.intermediate.dense          | Linear               | 2.4 M \n",
      "158 | bert_model.encoder.layer.8.output                      | BertOutput           | 2.4 M \n",
      "159 | bert_model.encoder.layer.8.output.dense                | Linear               | 2.4 M \n",
      "160 | bert_model.encoder.layer.8.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "161 | bert_model.encoder.layer.8.output.dropout              | Dropout              | 0     \n",
      "162 | bert_model.encoder.layer.9                             | BertLayer            | 7.1 M \n",
      "163 | bert_model.encoder.layer.9.attention                   | BertAttention        | 2.4 M \n",
      "164 | bert_model.encoder.layer.9.attention.self              | BertSelfAttention    | 1.8 M \n",
      "165 | bert_model.encoder.layer.9.attention.self.query        | Linear               | 590 K \n",
      "166 | bert_model.encoder.layer.9.attention.self.key          | Linear               | 590 K \n",
      "167 | bert_model.encoder.layer.9.attention.self.value        | Linear               | 590 K \n",
      "168 | bert_model.encoder.layer.9.attention.self.dropout      | Dropout              | 0     \n",
      "169 | bert_model.encoder.layer.9.attention.output            | BertSelfOutput       | 592 K \n",
      "170 | bert_model.encoder.layer.9.attention.output.dense      | Linear               | 590 K \n",
      "171 | bert_model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "172 | bert_model.encoder.layer.9.attention.output.dropout    | Dropout              | 0     \n",
      "173 | bert_model.encoder.layer.9.intermediate                | BertIntermediate     | 2.4 M \n",
      "174 | bert_model.encoder.layer.9.intermediate.dense          | Linear               | 2.4 M \n",
      "175 | bert_model.encoder.layer.9.output                      | BertOutput           | 2.4 M \n",
      "176 | bert_model.encoder.layer.9.output.dense                | Linear               | 2.4 M \n",
      "177 | bert_model.encoder.layer.9.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "178 | bert_model.encoder.layer.9.output.dropout              | Dropout              | 0     \n",
      "179 | bert_model.encoder.layer.10                            | BertLayer            | 7.1 M \n",
      "180 | bert_model.encoder.layer.10.attention                  | BertAttention        | 2.4 M \n",
      "181 | bert_model.encoder.layer.10.attention.self             | BertSelfAttention    | 1.8 M \n",
      "182 | bert_model.encoder.layer.10.attention.self.query       | Linear               | 590 K \n",
      "183 | bert_model.encoder.layer.10.attention.self.key         | Linear               | 590 K \n",
      "184 | bert_model.encoder.layer.10.attention.self.value       | Linear               | 590 K \n",
      "185 | bert_model.encoder.layer.10.attention.self.dropout     | Dropout              | 0     \n",
      "186 | bert_model.encoder.layer.10.attention.output           | BertSelfOutput       | 592 K \n",
      "187 | bert_model.encoder.layer.10.attention.output.dense     | Linear               | 590 K \n",
      "188 | bert_model.encoder.layer.10.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "189 | bert_model.encoder.layer.10.attention.output.dropout   | Dropout              | 0     \n",
      "190 | bert_model.encoder.layer.10.intermediate               | BertIntermediate     | 2.4 M \n",
      "191 | bert_model.encoder.layer.10.intermediate.dense         | Linear               | 2.4 M \n",
      "192 | bert_model.encoder.layer.10.output                     | BertOutput           | 2.4 M \n",
      "193 | bert_model.encoder.layer.10.output.dense               | Linear               | 2.4 M \n",
      "194 | bert_model.encoder.layer.10.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "195 | bert_model.encoder.layer.10.output.dropout             | Dropout              | 0     \n",
      "196 | bert_model.encoder.layer.11                            | BertLayer            | 7.1 M \n",
      "197 | bert_model.encoder.layer.11.attention                  | BertAttention        | 2.4 M \n",
      "198 | bert_model.encoder.layer.11.attention.self             | BertSelfAttention    | 1.8 M \n",
      "199 | bert_model.encoder.layer.11.attention.self.query       | Linear               | 590 K \n",
      "200 | bert_model.encoder.layer.11.attention.self.key         | Linear               | 590 K \n",
      "201 | bert_model.encoder.layer.11.attention.self.value       | Linear               | 590 K \n",
      "202 | bert_model.encoder.layer.11.attention.self.dropout     | Dropout              | 0     \n",
      "203 | bert_model.encoder.layer.11.attention.output           | BertSelfOutput       | 592 K \n",
      "204 | bert_model.encoder.layer.11.attention.output.dense     | Linear               | 590 K \n",
      "205 | bert_model.encoder.layer.11.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "206 | bert_model.encoder.layer.11.attention.output.dropout   | Dropout              | 0     \n",
      "207 | bert_model.encoder.layer.11.intermediate               | BertIntermediate     | 2.4 M \n",
      "208 | bert_model.encoder.layer.11.intermediate.dense         | Linear               | 2.4 M \n",
      "209 | bert_model.encoder.layer.11.output                     | BertOutput           | 2.4 M \n",
      "210 | bert_model.encoder.layer.11.output.dense               | Linear               | 2.4 M \n",
      "211 | bert_model.encoder.layer.11.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "212 | bert_model.encoder.layer.11.output.dropout             | Dropout              | 0     \n",
      "213 | bert_model.pooler                                      | BertPooler           | 590 K \n",
      "214 | bert_model.pooler.dense                                | Linear               | 590 K \n",
      "215 | bert_model.pooler.activation                           | Tanh                 | 0     \n",
      "216 | classifier                                             | SequenceClassifier   | 592 K \n",
      "217 | classifier.dropout                                     | Dropout              | 0     \n",
      "218 | classifier.mlp                                         | MultiLayerPerceptron | 592 K \n",
      "219 | classifier.mlp.layer0                                  | Linear               | 590 K \n",
      "220 | classifier.mlp.layer2                                  | Linear               | 1.5 K \n",
      "221 | loss                                                   | CrossEntropyLoss     | 0     \n",
      "222 | classification_report                                  | ClassificationReport | 0     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "\n",
      "    | Name                                                   | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                             | BertEncoder          | 109 M \n",
      "1   | bert_model.embeddings                                  | BertEmbeddings       | 23.8 M\n",
      "2   | bert_model.embeddings.word_embeddings                  | Embedding            | 23.4 M\n",
      "3   | bert_model.embeddings.position_embeddings              | Embedding            | 393 K \n",
      "4   | bert_model.embeddings.token_type_embeddings            | Embedding            | 1.5 K \n",
      "5   | bert_model.embeddings.LayerNorm                        | LayerNorm            | 1.5 K \n",
      "6   | bert_model.embeddings.dropout                          | Dropout              | 0     \n",
      "7   | bert_model.encoder                                     | BertEncoder          | 85.1 M\n",
      "8   | bert_model.encoder.layer                               | ModuleList           | 85.1 M\n",
      "9   | bert_model.encoder.layer.0                             | BertLayer            | 7.1 M \n",
      "10  | bert_model.encoder.layer.0.attention                   | BertAttention        | 2.4 M \n",
      "11  | bert_model.encoder.layer.0.attention.self              | BertSelfAttention    | 1.8 M \n",
      "12  | bert_model.encoder.layer.0.attention.self.query        | Linear               | 590 K \n",
      "13  | bert_model.encoder.layer.0.attention.self.key          | Linear               | 590 K \n",
      "14  | bert_model.encoder.layer.0.attention.self.value        | Linear               | 590 K \n",
      "15  | bert_model.encoder.layer.0.attention.self.dropout      | Dropout              | 0     \n",
      "16  | bert_model.encoder.layer.0.attention.output            | BertSelfOutput       | 592 K \n",
      "17  | bert_model.encoder.layer.0.attention.output.dense      | Linear               | 590 K \n",
      "18  | bert_model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "19  | bert_model.encoder.layer.0.attention.output.dropout    | Dropout              | 0     \n",
      "20  | bert_model.encoder.layer.0.intermediate                | BertIntermediate     | 2.4 M \n",
      "21  | bert_model.encoder.layer.0.intermediate.dense          | Linear               | 2.4 M \n",
      "22  | bert_model.encoder.layer.0.output                      | BertOutput           | 2.4 M \n",
      "23  | bert_model.encoder.layer.0.output.dense                | Linear               | 2.4 M \n",
      "24  | bert_model.encoder.layer.0.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "25  | bert_model.encoder.layer.0.output.dropout              | Dropout              | 0     \n",
      "26  | bert_model.encoder.layer.1                             | BertLayer            | 7.1 M \n",
      "27  | bert_model.encoder.layer.1.attention                   | BertAttention        | 2.4 M \n",
      "28  | bert_model.encoder.layer.1.attention.self              | BertSelfAttention    | 1.8 M \n",
      "29  | bert_model.encoder.layer.1.attention.self.query        | Linear               | 590 K \n",
      "30  | bert_model.encoder.layer.1.attention.self.key          | Linear               | 590 K \n",
      "31  | bert_model.encoder.layer.1.attention.self.value        | Linear               | 590 K \n",
      "32  | bert_model.encoder.layer.1.attention.self.dropout      | Dropout              | 0     \n",
      "33  | bert_model.encoder.layer.1.attention.output            | BertSelfOutput       | 592 K \n",
      "34  | bert_model.encoder.layer.1.attention.output.dense      | Linear               | 590 K \n",
      "35  | bert_model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "36  | bert_model.encoder.layer.1.attention.output.dropout    | Dropout              | 0     \n",
      "37  | bert_model.encoder.layer.1.intermediate                | BertIntermediate     | 2.4 M \n",
      "38  | bert_model.encoder.layer.1.intermediate.dense          | Linear               | 2.4 M \n",
      "39  | bert_model.encoder.layer.1.output                      | BertOutput           | 2.4 M \n",
      "40  | bert_model.encoder.layer.1.output.dense                | Linear               | 2.4 M \n",
      "41  | bert_model.encoder.layer.1.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "42  | bert_model.encoder.layer.1.output.dropout              | Dropout              | 0     \n",
      "43  | bert_model.encoder.layer.2                             | BertLayer            | 7.1 M \n",
      "44  | bert_model.encoder.layer.2.attention                   | BertAttention        | 2.4 M \n",
      "45  | bert_model.encoder.layer.2.attention.self              | BertSelfAttention    | 1.8 M \n",
      "46  | bert_model.encoder.layer.2.attention.self.query        | Linear               | 590 K \n",
      "47  | bert_model.encoder.layer.2.attention.self.key          | Linear               | 590 K \n",
      "48  | bert_model.encoder.layer.2.attention.self.value        | Linear               | 590 K \n",
      "49  | bert_model.encoder.layer.2.attention.self.dropout      | Dropout              | 0     \n",
      "50  | bert_model.encoder.layer.2.attention.output            | BertSelfOutput       | 592 K \n",
      "51  | bert_model.encoder.layer.2.attention.output.dense      | Linear               | 590 K \n",
      "52  | bert_model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "53  | bert_model.encoder.layer.2.attention.output.dropout    | Dropout              | 0     \n",
      "54  | bert_model.encoder.layer.2.intermediate                | BertIntermediate     | 2.4 M \n",
      "55  | bert_model.encoder.layer.2.intermediate.dense          | Linear               | 2.4 M \n",
      "56  | bert_model.encoder.layer.2.output                      | BertOutput           | 2.4 M \n",
      "57  | bert_model.encoder.layer.2.output.dense                | Linear               | 2.4 M \n",
      "58  | bert_model.encoder.layer.2.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "59  | bert_model.encoder.layer.2.output.dropout              | Dropout              | 0     \n",
      "60  | bert_model.encoder.layer.3                             | BertLayer            | 7.1 M \n",
      "61  | bert_model.encoder.layer.3.attention                   | BertAttention        | 2.4 M \n",
      "62  | bert_model.encoder.layer.3.attention.self              | BertSelfAttention    | 1.8 M \n",
      "63  | bert_model.encoder.layer.3.attention.self.query        | Linear               | 590 K \n",
      "64  | bert_model.encoder.layer.3.attention.self.key          | Linear               | 590 K \n",
      "65  | bert_model.encoder.layer.3.attention.self.value        | Linear               | 590 K \n",
      "66  | bert_model.encoder.layer.3.attention.self.dropout      | Dropout              | 0     \n",
      "67  | bert_model.encoder.layer.3.attention.output            | BertSelfOutput       | 592 K \n",
      "68  | bert_model.encoder.layer.3.attention.output.dense      | Linear               | 590 K \n",
      "69  | bert_model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "70  | bert_model.encoder.layer.3.attention.output.dropout    | Dropout              | 0     \n",
      "71  | bert_model.encoder.layer.3.intermediate                | BertIntermediate     | 2.4 M \n",
      "72  | bert_model.encoder.layer.3.intermediate.dense          | Linear               | 2.4 M \n",
      "73  | bert_model.encoder.layer.3.output                      | BertOutput           | 2.4 M \n",
      "74  | bert_model.encoder.layer.3.output.dense                | Linear               | 2.4 M \n",
      "75  | bert_model.encoder.layer.3.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "76  | bert_model.encoder.layer.3.output.dropout              | Dropout              | 0     \n",
      "77  | bert_model.encoder.layer.4                             | BertLayer            | 7.1 M \n",
      "78  | bert_model.encoder.layer.4.attention                   | BertAttention        | 2.4 M \n",
      "79  | bert_model.encoder.layer.4.attention.self              | BertSelfAttention    | 1.8 M \n",
      "80  | bert_model.encoder.layer.4.attention.self.query        | Linear               | 590 K \n",
      "81  | bert_model.encoder.layer.4.attention.self.key          | Linear               | 590 K \n",
      "82  | bert_model.encoder.layer.4.attention.self.value        | Linear               | 590 K \n",
      "83  | bert_model.encoder.layer.4.attention.self.dropout      | Dropout              | 0     \n",
      "84  | bert_model.encoder.layer.4.attention.output            | BertSelfOutput       | 592 K \n",
      "85  | bert_model.encoder.layer.4.attention.output.dense      | Linear               | 590 K \n",
      "86  | bert_model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "87  | bert_model.encoder.layer.4.attention.output.dropout    | Dropout              | 0     \n",
      "88  | bert_model.encoder.layer.4.intermediate                | BertIntermediate     | 2.4 M \n",
      "89  | bert_model.encoder.layer.4.intermediate.dense          | Linear               | 2.4 M \n",
      "90  | bert_model.encoder.layer.4.output                      | BertOutput           | 2.4 M \n",
      "91  | bert_model.encoder.layer.4.output.dense                | Linear               | 2.4 M \n",
      "92  | bert_model.encoder.layer.4.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "93  | bert_model.encoder.layer.4.output.dropout              | Dropout              | 0     \n",
      "94  | bert_model.encoder.layer.5                             | BertLayer            | 7.1 M \n",
      "95  | bert_model.encoder.layer.5.attention                   | BertAttention        | 2.4 M \n",
      "96  | bert_model.encoder.layer.5.attention.self              | BertSelfAttention    | 1.8 M \n",
      "97  | bert_model.encoder.layer.5.attention.self.query        | Linear               | 590 K \n",
      "98  | bert_model.encoder.layer.5.attention.self.key          | Linear               | 590 K \n",
      "99  | bert_model.encoder.layer.5.attention.self.value        | Linear               | 590 K \n",
      "100 | bert_model.encoder.layer.5.attention.self.dropout      | Dropout              | 0     \n",
      "101 | bert_model.encoder.layer.5.attention.output            | BertSelfOutput       | 592 K \n",
      "102 | bert_model.encoder.layer.5.attention.output.dense      | Linear               | 590 K \n",
      "103 | bert_model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "104 | bert_model.encoder.layer.5.attention.output.dropout    | Dropout              | 0     \n",
      "105 | bert_model.encoder.layer.5.intermediate                | BertIntermediate     | 2.4 M \n",
      "106 | bert_model.encoder.layer.5.intermediate.dense          | Linear               | 2.4 M \n",
      "107 | bert_model.encoder.layer.5.output                      | BertOutput           | 2.4 M \n",
      "108 | bert_model.encoder.layer.5.output.dense                | Linear               | 2.4 M \n",
      "109 | bert_model.encoder.layer.5.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "110 | bert_model.encoder.layer.5.output.dropout              | Dropout              | 0     \n",
      "111 | bert_model.encoder.layer.6                             | BertLayer            | 7.1 M \n",
      "112 | bert_model.encoder.layer.6.attention                   | BertAttention        | 2.4 M \n",
      "113 | bert_model.encoder.layer.6.attention.self              | BertSelfAttention    | 1.8 M \n",
      "114 | bert_model.encoder.layer.6.attention.self.query        | Linear               | 590 K \n",
      "115 | bert_model.encoder.layer.6.attention.self.key          | Linear               | 590 K \n",
      "116 | bert_model.encoder.layer.6.attention.self.value        | Linear               | 590 K \n",
      "117 | bert_model.encoder.layer.6.attention.self.dropout      | Dropout              | 0     \n",
      "118 | bert_model.encoder.layer.6.attention.output            | BertSelfOutput       | 592 K \n",
      "119 | bert_model.encoder.layer.6.attention.output.dense      | Linear               | 590 K \n",
      "120 | bert_model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "121 | bert_model.encoder.layer.6.attention.output.dropout    | Dropout              | 0     \n",
      "122 | bert_model.encoder.layer.6.intermediate                | BertIntermediate     | 2.4 M \n",
      "123 | bert_model.encoder.layer.6.intermediate.dense          | Linear               | 2.4 M \n",
      "124 | bert_model.encoder.layer.6.output                      | BertOutput           | 2.4 M \n",
      "125 | bert_model.encoder.layer.6.output.dense                | Linear               | 2.4 M \n",
      "126 | bert_model.encoder.layer.6.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "127 | bert_model.encoder.layer.6.output.dropout              | Dropout              | 0     \n",
      "128 | bert_model.encoder.layer.7                             | BertLayer            | 7.1 M \n",
      "129 | bert_model.encoder.layer.7.attention                   | BertAttention        | 2.4 M \n",
      "130 | bert_model.encoder.layer.7.attention.self              | BertSelfAttention    | 1.8 M \n",
      "131 | bert_model.encoder.layer.7.attention.self.query        | Linear               | 590 K \n",
      "132 | bert_model.encoder.layer.7.attention.self.key          | Linear               | 590 K \n",
      "133 | bert_model.encoder.layer.7.attention.self.value        | Linear               | 590 K \n",
      "134 | bert_model.encoder.layer.7.attention.self.dropout      | Dropout              | 0     \n",
      "135 | bert_model.encoder.layer.7.attention.output            | BertSelfOutput       | 592 K \n",
      "136 | bert_model.encoder.layer.7.attention.output.dense      | Linear               | 590 K \n",
      "137 | bert_model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "138 | bert_model.encoder.layer.7.attention.output.dropout    | Dropout              | 0     \n",
      "139 | bert_model.encoder.layer.7.intermediate                | BertIntermediate     | 2.4 M \n",
      "140 | bert_model.encoder.layer.7.intermediate.dense          | Linear               | 2.4 M \n",
      "141 | bert_model.encoder.layer.7.output                      | BertOutput           | 2.4 M \n",
      "142 | bert_model.encoder.layer.7.output.dense                | Linear               | 2.4 M \n",
      "143 | bert_model.encoder.layer.7.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "144 | bert_model.encoder.layer.7.output.dropout              | Dropout              | 0     \n",
      "145 | bert_model.encoder.layer.8                             | BertLayer            | 7.1 M \n",
      "146 | bert_model.encoder.layer.8.attention                   | BertAttention        | 2.4 M \n",
      "147 | bert_model.encoder.layer.8.attention.self              | BertSelfAttention    | 1.8 M \n",
      "148 | bert_model.encoder.layer.8.attention.self.query        | Linear               | 590 K \n",
      "149 | bert_model.encoder.layer.8.attention.self.key          | Linear               | 590 K \n",
      "150 | bert_model.encoder.layer.8.attention.self.value        | Linear               | 590 K \n",
      "151 | bert_model.encoder.layer.8.attention.self.dropout      | Dropout              | 0     \n",
      "152 | bert_model.encoder.layer.8.attention.output            | BertSelfOutput       | 592 K \n",
      "153 | bert_model.encoder.layer.8.attention.output.dense      | Linear               | 590 K \n",
      "154 | bert_model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "155 | bert_model.encoder.layer.8.attention.output.dropout    | Dropout              | 0     \n",
      "156 | bert_model.encoder.layer.8.intermediate                | BertIntermediate     | 2.4 M \n",
      "157 | bert_model.encoder.layer.8.intermediate.dense          | Linear               | 2.4 M \n",
      "158 | bert_model.encoder.layer.8.output                      | BertOutput           | 2.4 M \n",
      "159 | bert_model.encoder.layer.8.output.dense                | Linear               | 2.4 M \n",
      "160 | bert_model.encoder.layer.8.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "161 | bert_model.encoder.layer.8.output.dropout              | Dropout              | 0     \n",
      "162 | bert_model.encoder.layer.9                             | BertLayer            | 7.1 M \n",
      "163 | bert_model.encoder.layer.9.attention                   | BertAttention        | 2.4 M \n",
      "164 | bert_model.encoder.layer.9.attention.self              | BertSelfAttention    | 1.8 M \n",
      "165 | bert_model.encoder.layer.9.attention.self.query        | Linear               | 590 K \n",
      "166 | bert_model.encoder.layer.9.attention.self.key          | Linear               | 590 K \n",
      "167 | bert_model.encoder.layer.9.attention.self.value        | Linear               | 590 K \n",
      "168 | bert_model.encoder.layer.9.attention.self.dropout      | Dropout              | 0     \n",
      "169 | bert_model.encoder.layer.9.attention.output            | BertSelfOutput       | 592 K \n",
      "170 | bert_model.encoder.layer.9.attention.output.dense      | Linear               | 590 K \n",
      "171 | bert_model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "172 | bert_model.encoder.layer.9.attention.output.dropout    | Dropout              | 0     \n",
      "173 | bert_model.encoder.layer.9.intermediate                | BertIntermediate     | 2.4 M \n",
      "174 | bert_model.encoder.layer.9.intermediate.dense          | Linear               | 2.4 M \n",
      "175 | bert_model.encoder.layer.9.output                      | BertOutput           | 2.4 M \n",
      "176 | bert_model.encoder.layer.9.output.dense                | Linear               | 2.4 M \n",
      "177 | bert_model.encoder.layer.9.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "178 | bert_model.encoder.layer.9.output.dropout              | Dropout              | 0     \n",
      "179 | bert_model.encoder.layer.10                            | BertLayer            | 7.1 M \n",
      "180 | bert_model.encoder.layer.10.attention                  | BertAttention        | 2.4 M \n",
      "181 | bert_model.encoder.layer.10.attention.self             | BertSelfAttention    | 1.8 M \n",
      "182 | bert_model.encoder.layer.10.attention.self.query       | Linear               | 590 K \n",
      "183 | bert_model.encoder.layer.10.attention.self.key         | Linear               | 590 K \n",
      "184 | bert_model.encoder.layer.10.attention.self.value       | Linear               | 590 K \n",
      "185 | bert_model.encoder.layer.10.attention.self.dropout     | Dropout              | 0     \n",
      "186 | bert_model.encoder.layer.10.attention.output           | BertSelfOutput       | 592 K \n",
      "187 | bert_model.encoder.layer.10.attention.output.dense     | Linear               | 590 K \n",
      "188 | bert_model.encoder.layer.10.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "189 | bert_model.encoder.layer.10.attention.output.dropout   | Dropout              | 0     \n",
      "190 | bert_model.encoder.layer.10.intermediate               | BertIntermediate     | 2.4 M \n",
      "191 | bert_model.encoder.layer.10.intermediate.dense         | Linear               | 2.4 M \n",
      "192 | bert_model.encoder.layer.10.output                     | BertOutput           | 2.4 M \n",
      "193 | bert_model.encoder.layer.10.output.dense               | Linear               | 2.4 M \n",
      "194 | bert_model.encoder.layer.10.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "195 | bert_model.encoder.layer.10.output.dropout             | Dropout              | 0     \n",
      "196 | bert_model.encoder.layer.11                            | BertLayer            | 7.1 M \n",
      "197 | bert_model.encoder.layer.11.attention                  | BertAttention        | 2.4 M \n",
      "198 | bert_model.encoder.layer.11.attention.self             | BertSelfAttention    | 1.8 M \n",
      "199 | bert_model.encoder.layer.11.attention.self.query       | Linear               | 590 K \n",
      "200 | bert_model.encoder.layer.11.attention.self.key         | Linear               | 590 K \n",
      "201 | bert_model.encoder.layer.11.attention.self.value       | Linear               | 590 K \n",
      "202 | bert_model.encoder.layer.11.attention.self.dropout     | Dropout              | 0     \n",
      "203 | bert_model.encoder.layer.11.attention.output           | BertSelfOutput       | 592 K \n",
      "204 | bert_model.encoder.layer.11.attention.output.dense     | Linear               | 590 K \n",
      "205 | bert_model.encoder.layer.11.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "206 | bert_model.encoder.layer.11.attention.output.dropout   | Dropout              | 0     \n",
      "207 | bert_model.encoder.layer.11.intermediate               | BertIntermediate     | 2.4 M \n",
      "208 | bert_model.encoder.layer.11.intermediate.dense         | Linear               | 2.4 M \n",
      "209 | bert_model.encoder.layer.11.output                     | BertOutput           | 2.4 M \n",
      "210 | bert_model.encoder.layer.11.output.dense               | Linear               | 2.4 M \n",
      "211 | bert_model.encoder.layer.11.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "212 | bert_model.encoder.layer.11.output.dropout             | Dropout              | 0     \n",
      "213 | bert_model.pooler                                      | BertPooler           | 590 K \n",
      "214 | bert_model.pooler.dense                                | Linear               | 590 K \n",
      "215 | bert_model.pooler.activation                           | Tanh                 | 0     \n",
      "216 | classifier                                             | SequenceClassifier   | 592 K \n",
      "217 | classifier.dropout                                     | Dropout              | 0     \n",
      "218 | classifier.mlp                                         | MultiLayerPerceptron | 592 K \n",
      "219 | classifier.mlp.layer0                                  | Linear               | 590 K \n",
      "220 | classifier.mlp.layer2                                  | Linear               | 1.5 K \n",
      "221 | loss                                                   | CrossEntropyLoss     | 0     \n",
      "222 | classification_report                                  | ClassificationReport | 0     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "Restored states from the checkpoint file at /workspace/mount/results/sst2/checkpoints/trained-model-last.ckpt\n",
      "Restored states from the checkpoint file at /workspace/mount/results/sst2/checkpoints/trained-model-last.ckpt\n",
      "Validation sanity check:  50% 1/2 [00:00<00:00,  1.52it/s][NeMo I 2022-09-22 13:03:57 text_classification_model:166] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             97.50      81.25      88.64         48\n",
      "    label_id: 1                                             85.00      98.08      91.07         52\n",
      "    -------------------\n",
      "    micro avg                                               90.00      90.00      90.00        100\n",
      "    macro avg                                               91.25      89.66      89.85        100\n",
      "    weighted avg                                            91.00      90.00      89.90        100\n",
      "    \n",
      "Epoch 2: 100% 1053/1055 [03:10<00:00,  5.52it/s, loss=0.154, val_loss=0.219, lr=0]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100% 1055/1055 [03:11<00:00,  5.52it/s, loss=0.154, val_loss=0.219, lr=0][NeMo I 2022-09-22 13:07:09 text_classification_model:166] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             97.50      81.25      88.64         48\n",
      "    label_id: 1                                             85.00      98.08      91.07         52\n",
      "    -------------------\n",
      "    micro avg                                               90.00      90.00      90.00        100\n",
      "    macro avg                                               91.25      89.66      89.85        100\n",
      "    weighted avg                                            91.00      90.00      89.90        100\n",
      "    \n",
      "Epoch 2: 100% 1055/1055 [03:11<00:00,  5.52it/s, loss=0.154, val_loss=0.22, lr=0] \n",
      "                                             \u001b[AEpoch 2, global step 3158: val_loss reached 0.21950 (best 0.21950), saving model to \"/workspace/mount/results/sst2/checkpoints/trained-model---val_loss=0.22-epoch=2.ckpt\" as top 3\n",
      "Epoch 2, global step 3158: val_loss reached 0.21950 (best 0.21950), saving model to \"/workspace/mount/results/sst2/checkpoints/trained-model---val_loss=0.22-epoch=2.ckpt\" as top 3\n",
      "Epoch 2: 100% 1055/1055 [03:29<00:00,  5.04it/s, loss=0.154, val_loss=0.22, lr=0]Saving latest checkpoint...\n",
      "Saving latest checkpoint...\n",
      "Epoch 2: 100% 1055/1055 [04:11<00:00,  4.20it/s, loss=0.154, val_loss=0.22, lr=0]\n",
      "[NeMo I 2022-09-22 13:08:31 train:128] Experiment logs saved to '/workspace/mount/results/sst2'\n",
      "[NeMo I 2022-09-22 13:08:34 train:129] Trained model saved to '/workspace/mount/results/sst2/checkpoints/trained-model.tlt'\n",
      "2022-09-22 13:08:36,055 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n",
      "CPU times: user 2.87 s, sys: 799 ms, total: 3.67 s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# For BERT training on SST-2:\n",
    "!tao text_classification train \\\n",
    "    -e $SPECS_DIR/text_classification/train.yaml \\\n",
    "    -g 1  \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2 \\\n",
    "    training_ds.file_path=$DATA_DIR/SST-2/train.tsv \\\n",
    "    validation_ds.file_path=$DATA_DIR/SST-2/test.tsv \\\n",
    "    model.class_labels.class_labels_file=$DATA_DIR/SST-2/label_ids.csv \\\n",
    "    trainer.amp_level=\"01\" \\\n",
    "    trainer.precision=16 \\\n",
    "    trainer.max_epochs=3 \\\n",
    "    2>&1|tee my_assessment/step2.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train command produces a model file called `trained-model.tlt` saved at `results/sst2/checkpoints/trained-model.tlt`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 3: Infer and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Queries (not graded)\n",
    "Execute the following cell to create queries for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /dli/task/tao/specs/text_classification/infer.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SOURCE_MOUNT/specs/text_classification/infer.yaml\n",
    "\n",
    "# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.\n",
    "# TAO Spec file for inference using a previously pretrained BERT model for a text classification task.\n",
    "\n",
    "# \"Simulate\" user input: batch with four samples.\n",
    "input_batch:\n",
    "- \"this is a good script , good dialogue , funny even for adults .\"\n",
    "- \"the affectionate loopiness that once seemed congenital to demme s perspective has a tough time emerging from between the badly dated cutesy-pie mystery scenario a nd the newfangled hollywood post-production effects .\"\n",
    "- \" this piece of channel 5 grade trash is , quite frankly , an insult to the intelligence of the true genre enthusiast . \"\n",
    "- \"a delightful coming-of-age story .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on the Trained Model (not graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:35:58,156 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 12:35:58,249 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 12:36:01 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-09-22 12:36:04 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-09-22 12:36:04 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/sst2/checkpoints/trained-model.tlt\n",
      "    exp_manager:\n",
      "      task_name: infer\n",
      "      explicit_log_dir: /workspace/mount/results/sst2/infer\n",
      "    input_batch:\n",
      "    - this is a good script , good dialogue , funny even for adults .\n",
      "    - the affectionate loopiness that once seemed congenital to demme s perspective has\n",
      "      a tough time emerging from between the badly dated cutesy-pie mystery scenario a\n",
      "      nd the newfangled hollywood post-production effects .\n",
      "    - ' this piece of channel 5 grade trash is , quite frankly , an insult to the intelligence\n",
      "      of the true genre enthusiast . '\n",
      "    - a delightful coming-of-age story .\n",
      "    encryption_key: '*********'\n",
      "    \n",
      "[NeMo W 2022-09-22 12:36:04 exp_manager:26] Exp_manager is logging to `/workspace/mount/results/sst2/infer``, but it already exists.\n",
      "[NeMo W 2022-09-22 12:36:06 modelPT:193] Using /tmp/tmpdo1mgx8e/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140124923951328 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|█████████████████████████████| 570/570 [00:00<00:00, 1.02MB/s]\n",
      "Lock 140124923951328 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140124923950992 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 1.68MB/s]\n",
      "Lock 140124923950992 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140124924149824 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 45.6kB/s]\n",
      "Lock 140124924149824 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140124923952624 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 2.32MB/s]\n",
      "Lock 140124923952624 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-09-22 12:36:08 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140124923951856 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:05<00:00, 84.9MB/s]\n",
      "Lock 140124923951856 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo W 2022-09-22 12:36:16 modelPT:193] Using /tmp/tmpdo1mgx8e/label_ids.csv instead of /workspace/mount/data/SST-2/label_ids.csv.\n",
      "[NeMo I 2022-09-22 12:36:23 infer:103] The prediction results of some sample queries with the trained model:\n",
      "[NeMo I 2022-09-22 12:36:23 infer:105] Query: this is a good script , good dialogue , funny even for adults .\n",
      "[NeMo I 2022-09-22 12:36:23 infer:106] Predicted label: positive\n",
      "[NeMo I 2022-09-22 12:36:23 infer:105] Query: the affectionate loopiness that once seemed congenital to demme s perspective has a tough time emerging from between the badly dated cutesy-pie mystery scenario a nd the newfangled hollywood post-production effects .\n",
      "[NeMo I 2022-09-22 12:36:23 infer:106] Predicted label: negative\n",
      "[NeMo I 2022-09-22 12:36:23 infer:105] Query:  this piece of channel 5 grade trash is , quite frankly , an insult to the intelligence of the true genre enthusiast . \n",
      "[NeMo I 2022-09-22 12:36:23 infer:106] Predicted label: negative\n",
      "[NeMo I 2022-09-22 12:36:23 infer:105] Query: a delightful coming-of-age story .\n",
      "[NeMo I 2022-09-22 12:36:23 infer:106] Predicted label: positive\n",
      "[NeMo I 2022-09-22 12:36:23 infer:109] Experiment logs saved to '/workspace/mount/results/sst2/infer'\n",
      "2022-09-22 12:36:24,063 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# Run inference on user data:\n",
    "!tao text_classification infer \\\n",
    "    -e $SPECS_DIR/text_classification/infer.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your Model (results graded)\n",
    "Execute the following cell without changes.  Review your output to see if you had an F1 result above the 88% goal.  If not, you may need to retrain your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:36:31,369 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 12:36:31,479 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 12:36:34 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-09-22 12:36:37 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-09-22 12:36:38 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/sst2/checkpoints/trained-model.tlt\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/sst2/eval\n",
      "      exp_dir: null\n",
      "      name: null\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: false\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: false\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .nemo\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 1000\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 32\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: O2\n",
      "    test_ds:\n",
      "      file_path: /workspace/mount/data/SST-2/test.tsv\n",
      "      batch_size: 32\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "      num_workers: 3\n",
      "      drop_last: false\n",
      "      pin_memory: false\n",
      "    encryption_key: '********'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo W 2022-09-22 12:36:38 exp_manager:380] Exp_manager is logging to /workspace/mount/results/sst2/eval, but it already exists.\n",
      "[NeMo I 2022-09-22 12:36:38 exp_manager:194] Experiments will be logged at /workspace/mount/results/sst2/eval\n",
      "[NeMo W 2022-09-22 12:36:39 modelPT:193] Using /tmp/tmp4qns0lia/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 139987253049472 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100% 570/570 [00:00<00:00, 949kB/s]\n",
      "Lock 139987253049472 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 139987253050480 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 1.59MB/s]\n",
      "Lock 139987253050480 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 139987253089472 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100% 28.0/28.0 [00:00<00:00, 38.4kB/s]\n",
      "Lock 139987253089472 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 139987254528272 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100% 466k/466k [00:00<00:00, 3.36MB/s]\n",
      "Lock 139987254528272 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-09-22 12:36:41 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 139987253048896 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100% 440M/440M [00:04<00:00, 97.2MB/s] \n",
      "Lock 139987253048896 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo W 2022-09-22 12:36:49 modelPT:193] Using /tmp/tmp4qns0lia/label_ids.csv instead of /workspace/mount/data/SST-2/label_ids.csv.\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:120] Read 100 examples from /workspace/mount/data/SST-2/test.tsv.\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:239] example 0: ['not', 'the', 'kind', 'of', 'film', 'that', 'will', 'appeal', 'to', 'a', 'mainstream', 'american', 'audience', ',', 'but', 'there', 'is', 'a', 'certain', 'charm', 'about', 'the', 'film', 'that', 'makes', 'it', 'a', 'suitable', 'entry', 'into', 'the', 'fest', 'circuit', '.']\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:240] subtokens: [CLS] not the kind of film that will appeal to a mainstream american audience , but there is a certain charm about the film that makes it a suitable entry into the fest circuit . [SEP]\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:241] input_ids: 101 2025 1996 2785 1997 2143 2008 2097 5574 2000 1037 7731 2137 4378 1010 2021 2045 2003 1037 3056 11084 2055 1996 2143 2008 3084 2009 1037 7218 4443 2046 1996 17037 4984 1012 102\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:239] example 1: ['it', \"'s\", 'a', 'beautiful', 'madness', '.']\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:240] subtokens: [CLS] it ' s a beautiful madness . [SEP]\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:241] input_ids: 101 2009 1005 1055 1037 3376 12013 1012 102\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-09-22 12:36:53 text_classification_dataset:244] label: 1\n",
      "[NeMo I 2022-09-22 12:36:53 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-09-22 12:36:53 data_preprocessing:297] Min: 7 |                  Max: 54 |                  Mean: 25.85 |                  Median: 25.0\n",
      "[NeMo I 2022-09-22 12:36:53 data_preprocessing:303] 75 percentile: 34.00\n",
      "[NeMo I 2022-09-22 12:36:53 data_preprocessing:304] 99 percentile: 52.02\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Testing:  75% 3/4 [00:00<00:00,  2.10it/s][NeMo I 2022-09-22 12:36:54 text_classification_model:166] test_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             97.50      81.25      88.64         48\n",
      "    label_id: 1                                             85.00      98.08      91.07         52\n",
      "    -------------------\n",
      "    micro avg                                               90.00      90.00      90.00        100\n",
      "    macro avg                                               91.25      89.66      89.85        100\n",
      "    weighted avg                                            91.00      90.00      89.90        100\n",
      "    \n",
      "Testing: 100% 4/4 [00:00<00:00,  4.46it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_f1': tensor(90., device='cuda:0'),\n",
      " 'test_loss': tensor(0.1749, device='cuda:0'),\n",
      " 'test_precision': tensor(90., device='cuda:0'),\n",
      " 'test_recall': tensor(90., device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "[NeMo I 2022-09-22 12:36:55 evaluate:97] Experiment logs saved to '/workspace/mount/results/sst2/eval'\n",
      "2022-09-22 12:36:55,963 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# For BERT evaluation on SST-2:\n",
    "!tao text_classification evaluate \\\n",
    "    -e $SPECS_DIR/text_classification/evaluate.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/eval \\\n",
    "    test_ds.file_path=$DATA_DIR/SST-2/test.tsv \\\n",
    "    test_ds.batch_size=32 \\\n",
    "    test_ds.num_samples=-1 \\\n",
    "    2>&1|tee my_assessment/step3.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4: Export Custom Model\n",
    "### Export the Model for Riva (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:38:12,379 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-09-22 12:38:12,487 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-09-22 12:38:15 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-09-22 12:38:18 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-09-22 12:38:18 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/sst2/checkpoints/trained-model.tlt\n",
      "    export_to: tc-model.riva\n",
      "    export_format: RIVA\n",
      "    exp_manager:\n",
      "      task_name: export\n",
      "      explicit_log_dir: /workspace/mount/results/sst2/export/\n",
      "    encryption_key: '********'\n",
      "    \n",
      "[NeMo W 2022-09-22 12:38:18 exp_manager:26] Exp_manager is logging to `/workspace/mount/results/sst2/export/``, but it already exists.\n",
      "[NeMo W 2022-09-22 12:38:20 modelPT:193] Using /tmp/tmpkzge__cm/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 139830828149248 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100% 570/570 [00:00<00:00, 1.15MB/s]\n",
      "Lock 139830828149248 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 139830828148144 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 1.44MB/s]\n",
      "Lock 139830828148144 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 139830828159616 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100% 28.0/28.0 [00:00<00:00, 55.9kB/s]\n",
      "Lock 139830828159616 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 139830828149296 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100% 466k/466k [00:00<00:00, 2.33MB/s]\n",
      "Lock 139830828149296 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-09-22 12:38:22 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 139830828149152 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100% 440M/440M [00:04<00:00, 95.0MB/s] \n",
      "Lock 139830828149152 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo W 2022-09-22 12:38:30 modelPT:193] Using /tmp/tmpkzge__cm/label_ids.csv instead of /workspace/mount/data/SST-2/label_ids.csv.\n",
      "[NeMo I 2022-09-22 12:38:34 export:54] Model restored from '/workspace/mount/results/sst2/checkpoints/trained-model.tlt'\n",
      "Could not retrieve the artifact tokenizer.vocab_file used in tokenizer.vocab_file\n",
      "Could not retrieve the artifact label_ids.csv used in class_labels\n",
      "[NeMo I 2022-09-22 12:39:04 export:77] Experiment logs saved to '/workspace/mount/results/sst2/export'\n",
      "[NeMo I 2022-09-22 12:39:04 export:78] Exported model to '/workspace/mount/results/sst2/export/tc-model.riva'\n",
      "[NeMo I 2022-09-22 12:39:08 export:89] Exported model is compliant with Riva\n",
      "2022-09-22 12:39:09,627 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "#  For export to Riva:\n",
    "!tao text_classification export \\\n",
    "    -e $SPECS_DIR/text_classification/export.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/sst2/checkpoints/trained-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/sst2/export/ \\\n",
    "    export_format=RIVA \\\n",
    "    export_to=tc-model.riva \\\n",
    "    2>&1|tee my_assessment/step4.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export.log  tc-model.riva\n"
     ]
    }
   ],
   "source": [
    "# Check your work - does the exported tc-model.riva model exist?\n",
    "!ls $EXPORT_MODEL_LOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 5: Build and Deploy with Riva\n",
    "### Set up Project Paths (not graded)\n",
    "This block is complete, but feel free to add to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Riva paths for the project\n",
    "WORKSPACE = \"/dli/task\"\n",
    "\n",
    "##### Riva Paths\n",
    "# ServiceMaker Docker\n",
    "RIVA_SM_CONTAINER = \"nvcr.io/nvidia/riva/riva-speech:1.4.0-beta-servicemaker\"\n",
    "\n",
    "# Model output directories\n",
    "RMIR_LOC = WORKSPACE + \"/riva/riva_quickstart/models_repo_assessment/rmir\"\n",
    "RIVA_MODEL_LOC = WORKSPACE + '/riva/riva_quickstart/models_repo_assessment'\n",
    "\n",
    "# Model Names\n",
    "EXPORT_MODEL_NAME = \"tc-model.riva\"  \n",
    "RMIR_MODEL_NAME = \"tc-model.rmir\"\n",
    "\n",
    "# Riva Quick Start \n",
    "RIVA_QS = WORKSPACE + \"/riva/riva_quickstart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Deploy with Riva ServiceMaker (graded)\n",
    "Complete the <i><strong style=\"color:green;\">#FIXME</strong></i> line(s) and run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release devel (build 22382700)\n",
      "\n",
      "Copyright (c) 2018-2021, NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\n",
      "NVIDIA modifications are covered by the license terms that apply to the underlying\n",
      "project or file.\n",
      "\n",
      "NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for the inference server.  NVIDIA recommends the use of the following flags:\n",
      "   nvidia-docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "2022-09-22 12:40:54,400 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 12:40:54,453 [INFO] Packing binaries for self\n",
      "2022-09-22 12:40:55,534 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 12:40:55,582 [INFO] Trying to extract from model tc-model.riva\n",
      "2022-09-22 12:40:56,717 [INFO] Packing binaries for language_model\n",
      "2022-09-22 12:40:57,795 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 12:40:57,843 [INFO] Trying to extract from model tc-model.riva\n",
      "2022-09-22 12:41:03,471 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 12:41:03,519 [INFO] Trying to extract from model tc-model.riva\n",
      "2022-09-22 12:41:04,648 [INFO] Packing binaries for tokenizer\n",
      "2022-09-22 12:41:05,738 [ERROR] Condition for key 'runtime' (PyTorch  <built-in function eq> ONNX) is not fulfilled\n",
      "2022-09-22 12:41:05,786 [INFO] Trying to extract from model tc-model.riva\n"
     ]
    }
   ],
   "source": [
    "# Syntax: riva-build <task-name> output-dir-for-rmir/model.rmir:key dir-for-riva/model.riva:key\n",
    "!docker run --rm --gpus 1 \\\n",
    "    -v $EXPORT_MODEL_LOC:/tao \\\n",
    "    -v $RMIR_LOC:/riva \\\n",
    "    $RIVA_SM_CONTAINER -- \\\n",
    "    riva-build text_classification -f /riva/$RMIR_MODEL_NAME:$KEY /tao/$EXPORT_MODEL_NAME:$KEY \\\n",
    "    2>&1|tee my_assessment/step5.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tc-model.rmir\n"
     ]
    }
   ],
   "source": [
    "# Check your work - does the exported tc-model.rmir model exist?\n",
    "!ls $RMIR_LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release devel (build 22382700)\n",
      "\n",
      "Copyright (c) 2018-2021, NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\n",
      "NVIDIA modifications are covered by the license terms that apply to the underlying\n",
      "project or file.\n",
      "\n",
      "NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for the inference server.  NVIDIA recommends the use of the following flags:\n",
      "   nvidia-docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "2022-09-22 12:41:44,122 [INFO] Writing Riva model repository to '/data/models/'...\n",
      "2022-09-22 12:41:44,122 [INFO] The riva model repo target directory is /data/models/\n",
      "2022-09-22 12:41:45,194 [INFO] Extract_binaries for tokenizer -> /data/models/riva_tokenizer/1\n",
      "2022-09-22 12:41:45,196 [INFO] Extract_binaries for language_model -> /data/models/riva-trt-riva_text_classification_default-nn-bert-base-uncased/1\n",
      "2022-09-22 12:41:48,899 [INFO] Printing copied artifacts:\n",
      "2022-09-22 12:41:48,899 [INFO] {'ckpt': '/data/models/riva-trt-riva_text_classification_default-nn-bert-base-uncased/1/model_weights.ckpt', 'bert_config_file': '/data/models/riva-trt-riva_text_classification_default-nn-bert-base-uncased/1/bert-base-uncased_encoder_config.json'}\n",
      "2022-09-22 12:41:48,899 [INFO] Building TRT engine from PyTorch Checkpoint\n",
      "2022-09-22 12:43:02,987 [INFO] Text Classification classes:2\n",
      "2022-09-22 12:43:03,039 [INFO] Extract_binaries for self -> /data/models/riva_text_classification_default/1\n"
     ]
    }
   ],
   "source": [
    "# Syntax: riva-deploy -f dir-for-rmir/model.rmir:key output-dir-for-repository\n",
    "!docker run --rm --gpus 1 \\\n",
    "    -v $RIVA_MODEL_LOC:/data \\\n",
    "    $RIVA_SM_CONTAINER -- \\\n",
    "    riva-deploy -f /data/rmir/tc-model.rmir:$KEY \\\n",
    "    /data/models/ \\\n",
    "    2>&1|tee -a my_assessment/step5.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riva-trt-riva_text_classification_default-nn-bert-base-uncased\triva_tokenizer\n",
      "riva_text_classification_default\n"
     ]
    }
   ],
   "source": [
    "# Check your work - are there optimized models for text classification?\n",
    "!ls $RIVA_MODEL_LOC/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dli/task/riva/riva_quickstart/models_repo_assessment'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RIVA_MODEL_LOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 6: Start Riva Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Start Riva (graded)\n",
    "Next, modify the [config.sh](riva/riva_quickstart/config.sh) to enable relevant Riva services. \n",
    "In this case, we want to start NLP services, provide the encryption key, and update the path to the model repository (`RIVA_MODEL_LOC`). \n",
    "Open the [config.sh](riva/riva_quickstart/config.sh) and make changes where necessary, then start the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Riva Speech Services. This may take several minutes depending on the number of models deployed.\n",
      "Waiting for Riva server to load all models...retrying in 10 seconds\n",
      "Waiting for Riva server to load all models...retrying in 10 seconds\n",
      "Riva server is ready...\n"
     ]
    }
   ],
   "source": [
    "# Run Riva Start. This will deploy the model.\n",
    "!cd $RIVA_QS && bash riva_start.sh config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release 21.07 (build 25292380)\n",
      "\n",
      "Copyright (c) 2018-2021, NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\n",
      "NVIDIA modifications are covered by the license terms that apply to the underlying\n",
      "project or file.\n",
      "\n",
      "NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for the inference server.  NVIDIA recommends the use of the following flags:\n",
      "   nvidia-docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "I0922 12:46:55.490140 76 metrics.cc:228] Collecting metrics for GPU 0: Tesla T4\n",
      "I0922 12:46:55.502588 76 onnxruntime.cc:1722] TRITONBACKEND_Initialize: onnxruntime\n",
      "I0922 12:46:55.502632 76 onnxruntime.cc:1732] Triton TRITONBACKEND API version: 1.0\n",
      "I0922 12:46:55.502636 76 onnxruntime.cc:1738] 'onnxruntime' TRITONBACKEND API version: 1.0\n",
      "I0922 12:46:55.684943 76 pinned_memory_manager.cc:206] Pinned memory pool is created at '0x7f2dc4000000' with size 268435456\n",
      "I0922 12:46:55.685354 76 cuda_memory_manager.cc:103] CUDA memory pool is created on device 0 with size 1000000000\n",
      "I0922 12:46:55.688559 76 model_repository_manager.cc:1066] loading: riva_tokenizer:1\n",
      "I0922 12:46:55.788948 76 model_repository_manager.cc:1066] loading: riva-trt-riva_text_classification_default-nn-bert-base-uncased:1\n",
      "I0922 12:46:55.789209 76 custom_backend.cc:198] Creating instance riva_tokenizer_0_0_cpu on CPU using libtriton_riva_nlp_tokenizer.so\n",
      "I0922 12:46:55.803791 76 model_repository_manager.cc:1240] successfully loaded 'riva_tokenizer' version 1\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "I0922 12:47:08.196861 76 plan_backend.cc:384] Creating instance riva-trt-riva_text_classification_default-nn-bert-base-uncased_0_0_gpu0 on GPU 0 (7.5) using model.plan\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "I0922 12:47:09.397976 76 plan_backend.cc:768] Created instance riva-trt-riva_text_classification_default-nn-bert-base-uncased_0_0_gpu0 on GPU 0 with stream priority 0 and optimization profile default[0];\n",
      "I0922 12:47:09.398680 76 model_repository_manager.cc:1240] successfully loaded 'riva-trt-riva_text_classification_default-nn-bert-base-uncased' version 1\n",
      "I0922 12:47:09.398904 76 model_repository_manager.cc:1066] loading: riva_text_classification_default:1\n",
      "  > Riva waiting for Triton server to load all models...retrying in 1 second\n",
      "I0922 12:47:09.499178 76 model_repository_manager.cc:1240] successfully loaded 'riva_text_classification_default' version 1\n",
      "I0922 12:47:09.499234 76 server.cc:504] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0922 12:47:09.499262 76 server.cc:543] \n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "| Backend     | Path                                                            | Config |\n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "| tensorrt    | <built-in>                                                      | {}     |\n",
      "| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {}     |\n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "\n",
      "I0922 12:47:09.499298 76 server.cc:586] \n",
      "+----------------------------------------------------------------+---------+--------+\n",
      "| Model                                                          | Version | Status |\n",
      "+----------------------------------------------------------------+---------+--------+\n",
      "| riva-trt-riva_text_classification_default-nn-bert-base-uncased | 1       | READY  |\n",
      "| riva_text_classification_default                               | 1       | READY  |\n",
      "| riva_tokenizer                                                 | 1       | READY  |\n",
      "+----------------------------------------------------------------+---------+--------+\n",
      "\n",
      "I0922 12:47:09.499382 76 tritonserver.cc:1658] \n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                  |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                 |\n",
      "| server_version                   | 2.9.0                                                                                                                                                                                  |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics |\n",
      "| model_repository_path[0]         | /data/models                                                                                                                                                                           |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                              |\n",
      "| strict_model_config              | 1                                                                                                                                                                                      |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                              |\n",
      "| cuda_memory_pool_byte_size{0}    | 1000000000                                                                                                                                                                             |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                    |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                      |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                     |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0922 12:47:09.500464 76 grpc_server.cc:4028] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0922 12:47:09.500688 76 http_server.cc:2761] Started HTTPService at 0.0.0.0:8000\n",
      "I0922 12:47:09.543164 76 http_server.cc:2780] Started Metrics Service at 0.0.0.0:8002\n",
      "  > Triton server is ready...\n",
      "I0922 12:47:10.445364   165 grpc_health.cc:27] RivaHealthService initialized with server: localhost:8001\n",
      "I0922 12:47:10.445398   165 grpc_riva_asr.cc:148] Setting uri for ASRServiceImpl\n",
      "I0922 12:47:10.445401   165 grpc_riva_asr.cc:149] Initializing different models\n",
      "I0922 12:47:10.445784   165 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 12:47:10.446386   165 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 12:47:10.446571   165 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 12:47:10.446579   165 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 12:47:10.448549   165 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 12:47:10.449122   165 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 12:47:10.449714   165 model_registry.cc:109] Successfully registered: 0 models.\n",
      "I0922 12:47:10.449723   165 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 12:47:10.449883   165 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 12:47:10.450949   165 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 12:47:10.451783   165 grpc_riva_asr.cc:173] Punctuation model does not exist on server\n",
      "I0922 12:47:10.451793   165 grpc_riva_asr.cc:177] Seeding RNG used for correlation id with time: 1663850830\n",
      "I0922 12:47:10.483180   165 grpc_riva_asr.cc:148] Setting uri for ASRServiceImpl\n",
      "I0922 12:47:10.483196   165 grpc_riva_asr.cc:149] Initializing different models\n",
      "I0922 12:47:10.483202   165 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 12:47:10.483556   165 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 12:47:10.483697   165 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 12:47:10.483705   165 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 12:47:10.484320   165 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 12:47:10.484879   165 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 12:47:10.485456   165 model_registry.cc:109] Successfully registered: 0 models.\n",
      "I0922 12:47:10.485468   165 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 12:47:10.485616   165 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 12:47:10.486668   165 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 12:47:10.487265   165 grpc_riva_asr.cc:173] Punctuation model does not exist on server\n",
      "I0922 12:47:10.487275   165 grpc_riva_asr.cc:177] Seeding RNG used for correlation id with time: 1663850830\n",
      "I0922 12:47:10.515125   165 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 12:47:10.515398   165 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 12:47:10.516489   165 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 12:47:10.517053   165 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 12:47:10.517302   165 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 12:47:10.517450   165 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 12:47:10.517458   165 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 12:47:10.517961   165 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 12:47:10.518502   165 model_registry.cc:104] 'Successfully registering riva_text_classification_default'\n",
      "I0922 12:47:10.518522   165 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 12:47:10.519052   165 model_registry.cc:109] Successfully registered: 1 models.\n",
      "I0922 12:47:10.519062   165 grpc_riva_nlp.cc:33] NLPService GRPC service started\n",
      "I0922 12:47:10.519066   165 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 12:47:10.519215   165 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 12:47:10.520232   165 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 12:47:10.520784   165 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 12:47:10.520988   165 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 12:47:10.521112   165 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 12:47:10.521119   165 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 12:47:10.521613   165 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 12:47:10.522118   165 model_registry.cc:104] 'Successfully registering riva_text_classification_default'\n",
      "I0922 12:47:10.522136   165 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 12:47:10.522666   165 model_registry.cc:109] Successfully registered: 1 models.\n",
      "I0922 12:47:10.522675   165 grpc_riva_nlp.cc:33] NLPService GRPC service started\n",
      "I0922 12:47:10.522680   165 client.cc:38] RivaLanguageUnderstandingClient initialized with server: localhost:8001\n",
      "I0922 12:47:10.522809   165 client.cc:54] Our model repository has: 3 models.\n",
      "I0922 12:47:10.523797   165 client.cc:72] Registering 'riva_text_classification_default' with service '/nvidia.riva.nlp.RivaLanguageUnderstanding/ClassifyText'\n",
      "I0922 12:47:10.524349   165 model_registry.cc:36] RivaModelRegistry initialized with server: localhost:8001\n",
      "I0922 12:47:10.524569   165 model_registry.cc:65] Server Name: triton, Server version: 2.9.0\n",
      "I0922 12:47:10.524688   165 model_registry.cc:86] Our model repository has a total of: 3 models\n",
      "I0922 12:47:10.524694   165 model_registry.cc:91] Model names: riva-trt-riva_text_classification_default-nn-bert-base-uncased, Model version: 1\n",
      "I0922 12:47:10.525182   165 model_registry.cc:91] Model names: riva_text_classification_default, Model version: 1\n",
      "I0922 12:47:10.525696   165 model_registry.cc:104] 'Successfully registering riva_text_classification_default'\n",
      "I0922 12:47:10.525714   165 model_registry.cc:91] Model names: riva_tokenizer, Model version: 1\n",
      "I0922 12:47:10.526244   165 model_registry.cc:109] Successfully registered: 1 models.\n",
      "I0922 12:47:10.526253   165 grpc_riva_nlp.cc:33] NLPService GRPC service started\n",
      "I0922 12:47:10.526463   165 riva_server.cc:91] NLP Service connected to Triton at localhost:8001\n",
      "I0922 12:47:10.526472   165 riva_server.cc:93] ASR Service connected to Triton at localhost:8001\n",
      "I0922 12:47:10.526474   165 riva_server.cc:96] Riva Conversational AI Server listening on 0.0.0.0:50051\n"
     ]
    }
   ],
   "source": [
    "# Check Riva running services \n",
    "!docker logs riva-speech \\\n",
    "    2>&1|tee my_assessment/step6.txt # DO NOT REMOVE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riva Service Request (not graded)\n",
    "Although the SST-2 data set is trained on movie sentiments, it will likely work in our restaurant domain too.  Give it a try with the following queries or make up your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client app to test text classification on Riva\n",
      "Using model: riva_text_classification_default\n",
      "[('positive', 0.9643549919128418)]\n",
      "Client app to test text classification on Riva\n",
      "Using model: riva_text_classification_default\n",
      "[('negative', 0.9125980138778687)]\n",
      "Client app to test text classification on Riva\n",
      "Using model: riva_text_classification_default\n",
      "[('positive', 0.9946290254592896)]\n"
     ]
    }
   ],
   "source": [
    "%run my_assessment/sentiment_analysis_client.py --query \"I like pizza\"\n",
    "%run my_assessment/sentiment_analysis_client.py --query \"I don't like this restaurant\"\n",
    "%run my_assessment/sentiment_analysis_client.py --query \"yeah, sounds good\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Riva Services "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down docker containers...\n"
     ]
    }
   ],
   "source": [
    "# Shut down Riva \n",
    "!bash $RIVA_QS/riva_stop.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 7: Submit You Assessment\n",
    "How were your results? \n",
    "\n",
    "If you are satisfied that you have completed the code correctly, and that your training and deployment are correct, you can submit your project as follows to the autograder:\n",
    "\n",
    "1. Go back to the GPU launch page and click the checkmark to run the assessment:\n",
    "\n",
    "<img src=\"images/assess/assessment_checkmark.png\">\n",
    "\n",
    "2. That's it!  You'll receive your grade feedback in the pop-up window. \n",
    "\n",
    "<img src=\"images/assess/assessment_pass_popup.png\">\n",
    "\n",
    "You can check your assessment progress in the course progress tab.  Note that partial values for the coding assessment **won't be visible here - it shows up as either 0 (if you achieve <65) or the full 70 points**.  Be sure to complete the additional questions to qualify for your final certificate!\n",
    "\n",
    "<img src=\"images/assess/progress.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
